Start time: 2025-03-28 22:39:57
Namespace(num_layers=3, epochs=200, dim_hidden=64, repeat_times=3, linear_sparsity=0.3125, train_mode='score_only', rerand_freq=0, exp_name='Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molbace_Msup_L3_M16_S3125', weight_l1=0.0, sampling=None, samplingtype=None, sparse_decay=True, attack=None, auroc=False, attack_eps=0, dataset='ogbg-molbace', random_seed=None, resume=False, cuda=True, type_model='GCN_graph_UGTs', dropout=0.0, lr=0.01, weight_decay=0.0005, transductive=True, activation='relu', type_norm='batch', command='train', force_restart=False, seed_by_time=True, print_train_loss=False, num_gpus=1, output_dir='__outputs__', sync_dir='__sync__', save_best_model=True, optimizer='Adam', scheduler='CustomCosineLR', warm_epochs=0, finetuning_epochs=0, finetuning_lr=None, lr_milestones=[900, 1000, 1100], checkpoint_epochs=[], multisteplr_gamma=0.1, learning_framework='GraphLevelLearning', bn_track_running_stats=True, bn_affine=True, bn_momentum=0.1, init_mode='xor16_offset', init_mode_mask='kaiming_uniform', init_mode_linear=None, init_scale=1.0, init_scale_score=1.0, heads=1, sparsity_list=[0.3125, 0.541667, 0.770833], num_mask=3, enable_mask=True, enable_abs_comp=True, validate=False, pretrained_path=None, prunedw_path=None, enable_sw_mm=False, BN_GIN=False, evatime=False, drawadj=False, evanum=50, METIS=False, spadj=False, adjsparsity_ratio=0.0, enable_feat_pruning=False, featsparsity_ratio=0.0, enable_node_pruning=False, x_pruning_layer=0, regular_weight_pruning=None, num_of_weight_blocks=1, global_th_for_rowbyrow=False, download_prunedw=False, gra_part=False, no_edge_weight=False, sparse_tensor=False, original_edge_weight=False, only_train_data=False, flowgnn_debug=False, nmsparsity=True, M=16, unstructured_for_last_layer=False, xor_seed_using_instance_number=False, outgoing_centroids=False, folded_layer=0, BN_track_running_stats=True, folded_SM=False, half_folded=False, batch_size=64, elastic_net=False, elastic_lambda=5e-08, l1_ratio=0.5, no_norm=False, adp=False, SLT_Bonder=False, SLTAtom=True, SLTBond=True, SLTRoot=False, SLTAtom_ini='xor16_atom', SLTBond_ini='xor16_bond', SLTRoot_ini='default', dense_for_last_layer=True, local_pruning=False, local_sparsity_list=None, inference_time=False, sparsity_profiling=False, nm_decay=0.0001, num_feats=9, num_classes=2)
GCN_graph_UGTs(
  (convs): ModuleList(
    (0): Graphlevel_GCNConv(64, 64)
    (1): Graphlevel_GCNConv(64, 64)
    (2): Graphlevel_GCNConv(64, 64)
  )
  (atom_encoder): SLT_AtomEncoder(
    (atom_embedding_list): ModuleList(
      (0): Embedding(119, 64)
      (1): Embedding(5, 64)
      (2): Embedding(12, 64)
      (3): Embedding(12, 64)
      (4): Embedding(10, 64)
      (5): Embedding(6, 64)
      (6): Embedding(6, 64)
      (7): Embedding(2, 64)
      (8): Embedding(2, 64)
    )
    (weight_scores_list): ParameterList(
        (0): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (1): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (2): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (3): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (4): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (5): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (6): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (7): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (8): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
    )
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (graph_pred_linear): Linear(in_features=64, out_features=1, bias=True)
)
Name: convs.0.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.0.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.0.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.0.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.0.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.0.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.1.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.1.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.1.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.1.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.1.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.2.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.2.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.2.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.2.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.2.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.atom_embedding_list.0.weight, Shape: torch.Size([119, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.1.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.2.weight, Shape: torch.Size([12, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.3.weight, Shape: torch.Size([12, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.4.weight, Shape: torch.Size([10, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.5.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.6.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.7.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.8.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: atom_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.3, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.4, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.5, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.6, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.7, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.8, Shape: torch.Size([1, 64]), Requires Grad: True
Name: batch_norms.0.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.0.bias, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.1.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.1.bias, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.2.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.2.bias, Shape: torch.Size([64]), Requires Grad: True
Name: graph_pred_linear.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: graph_pred_linear.bias, Shape: torch.Size([1]), Requires Grad: True
/artic/h-ito/BingoGCN/__outputs__/Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molbace_Msup_L3_M16_S3125/dump..Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molbace_Msup_L3_M16_S3125.pth
0 train_acc 0.277314497716895
1 train_acc 0.5927739726027398
2 train_acc 0.5641324200913242
3 train_acc 0.5230051369863014
4 train_acc 0.4599486301369863
5 train_acc 0.45498287671232873
6 train_acc 0.4404480593607306
7 train_acc 0.4399058219178082
8 train_acc 0.431652397260274
9 train_acc 0.4331877853881278
10 train_acc 0.4396603881278539
11 train_acc 0.3798458904109589
12 train_acc 0.4007305936073059
13 train_acc 0.42437499999999995
14 train_acc 0.4199514840182649
15 train_acc 0.4131107305936073
16 train_acc 0.42149543378995435
17 train_acc 0.4123829908675799
18 train_acc 0.3900085616438356
19 train_acc 0.41283105022831046
20 train_acc 0.4129880136986301
21 train_acc 0.37803082191780824
22 train_acc 0.4096917808219178
23 train_acc 0.40532106164383563
24 train_acc 0.42782534246575343
25 train_acc 0.4224429223744292
26 train_acc 0.41921232876712333
27 train_acc 0.4131150114155251
28 train_acc 0.3953881278538813
29 train_acc 0.4087200342465753
30 train_acc 0.412314497716895
31 train_acc 0.4190981735159818
32 train_acc 0.388861301369863
33 train_acc 0.3906506849315069
34 train_acc 0.40016267123287674
35 train_acc 0.38187785388127854
36 train_acc 0.3920091324200914
37 train_acc 0.388533105022831
38 train_acc 0.4096632420091324
39 train_acc 0.3982505707762557
40 train_acc 0.38433789954337905
41 train_acc 0.4144235159817351
42 train_acc 0.43017551369863016
43 train_acc 0.39315068493150684
44 train_acc 0.42262699771689494
45 train_acc 0.41136415525114156
46 train_acc 0.40994863013698635
47 train_acc 0.37580479452054794
48 train_acc 0.4166723744292238
49 train_acc 0.39949486301369863
50 train_acc 0.41134988584474885
51 train_acc 0.3967665525114155
52 train_acc 0.41511843607305937
53 train_acc 0.4085958904109589
54 train_acc 0.40093607305936074
55 train_acc 0.4205793378995434
56 train_acc 0.4156792237442922
57 train_acc 0.4279680365296803
58 train_acc 0.3858390410958904
59 train_acc 0.4010245433789954
60 train_acc 0.4063584474885845
61 train_acc 0.4156021689497717
62 train_acc 0.4244620433789954
63 train_acc 0.41676940639269405
64 train_acc 0.43266837899543376
65 train_acc 0.4256877853881278
66 train_acc 0.421361301369863
67 train_acc 0.39686073059360727
68 train_acc 0.440439497716895
69 train_acc 0.4132990867579909
70 train_acc 0.419009703196347
71 train_acc 0.38772117579908677
72 train_acc 0.4075057077625571
73 train_acc 0.40827625570776255
74 train_acc 0.40777682648401825
75 train_acc 0.4050970319634703
76 train_acc 0.4105222602739726
77 train_acc 0.42397831050228313
78 train_acc 0.43406392694063933
79 train_acc 0.41154965753424655
80 train_acc 0.4101940639269406
81 train_acc 0.4247802511415525
82 train_acc 0.3817594178082192
83 train_acc 0.4342722602739726
84 train_acc 0.44743436073059356
85 train_acc 0.43398687214611875
86 train_acc 0.43112442922374433
87 train_acc 0.41828196347031965
88 train_acc 0.4361501141552511
89 train_acc 0.4275970319634703
90 train_acc 0.43695205479452054
91 train_acc 0.4514583333333334
92 train_acc 0.44038527397260274
93 train_acc 0.4538498858447489
94 train_acc 0.43581050228310503
95 train_acc 0.4352939497716895
96 train_acc 0.4342351598173516
97 train_acc 0.41408675799086764
98 train_acc 0.4422060502283105
99 train_acc 0.43357305936073054
100 train_acc 0.39250285388127854 val_acc 0.5945054945054945 test_acc 0.6661450182576943
101 train_acc 0.4142665525114154 val_acc 0.554945054945055 test_acc 0.6661450182576943
102 train_acc 0.42238869863013695 val_acc 0.5051282051282052 test_acc 0.6661450182576943
103 train_acc 0.4006107305936073 val_acc 0.4512820512820513 test_acc 0.6661450182576943
104 train_acc 0.43118150684931505 val_acc 0.38021978021978026 test_acc 0.6661450182576943
105 train_acc 0.41986872146118726 val_acc 0.3827838827838828 test_acc 0.6661450182576943
106 train_acc 0.44577054794520543 val_acc 0.5710622710622711 test_acc 0.6661450182576943
107 train_acc 0.43057505707762556 val_acc 0.3992673992673993 test_acc 0.6661450182576943
108 train_acc 0.43614297945205477 val_acc 0.5102564102564102 test_acc 0.6661450182576943
109 train_acc 0.42744292237442927 val_acc 0.5831501831501832 test_acc 0.6661450182576943
110 train_acc 0.43955764840182643 val_acc 0.5336996336996337 test_acc 0.6661450182576943
111 train_acc 0.4020148401826484 val_acc 0.43846153846153846 test_acc 0.6661450182576943
112 train_acc 0.4166466894977169 val_acc 0.5073260073260073 test_acc 0.6661450182576943
113 train_acc 0.4185673515981735 val_acc 0.584981684981685 test_acc 0.6661450182576943
114 train_acc 0.4549814497716895 val_acc 0.528937728937729 test_acc 0.6661450182576943
115 train_acc 0.42816352739726027 val_acc 0.6095238095238096 test_acc 0.7155277343070771
116 train_acc 0.44537956621004565 val_acc 0.5124542124542125 test_acc 0.7155277343070771
117 train_acc 0.4408219178082192 val_acc 0.5963369963369963 test_acc 0.7155277343070771
118 train_acc 0.4440839041095891 val_acc 0.5732600732600732 test_acc 0.7155277343070771
119 train_acc 0.4485017123287671 val_acc 0.584981684981685 test_acc 0.7155277343070771
120 train_acc 0.44205051369863013 val_acc 0.3816849816849817 test_acc 0.7155277343070771
121 train_acc 0.4115582191780822 val_acc 0.45018315018315025 test_acc 0.7155277343070771
122 train_acc 0.4446375570776256 val_acc 0.5131868131868133 test_acc 0.7155277343070771
123 train_acc 0.4525485159817352 val_acc 0.5813186813186814 test_acc 0.7155277343070771
124 train_acc 0.4486558219178082 val_acc 0.626007326007326 test_acc 0.7155277343070771
125 train_acc 0.44104737442922376 val_acc 0.6534798534798535 test_acc 0.7155277343070771
126 train_acc 0.4078938356164383 val_acc 0.504029304029304 test_acc 0.7155277343070771
127 train_acc 0.4519377853881279 val_acc 0.591941391941392 test_acc 0.7155277343070771
128 train_acc 0.4451227168949771 val_acc 0.3941391941391941 test_acc 0.7155277343070771
129 train_acc 0.45165525114155247 val_acc 0.46923076923076923 test_acc 0.7155277343070771
130 train_acc 0.43926655251141555 val_acc 0.6184981684981685 test_acc 0.7155277343070771
131 train_acc 0.4267037671232877 val_acc 0.4956043956043957 test_acc 0.7155277343070771
132 train_acc 0.4545918949771689 val_acc 0.5750915750915752 test_acc 0.7155277343070771
133 train_acc 0.4500485159817351 val_acc 0.49157509157509166 test_acc 0.7155277343070771
134 train_acc 0.45980022831050227 val_acc 0.5326007326007326 test_acc 0.7155277343070771
135 train_acc 0.44319777397260274 val_acc 0.49267399267399276 test_acc 0.7155277343070771
136 train_acc 0.45299372146118716 val_acc 0.6212454212454213 test_acc 0.7240479916536254
137 train_acc 0.43881278538812785 val_acc 0.4586080586080586 test_acc 0.7240479916536254
138 train_acc 0.4368464611872146 val_acc 0.5923076923076924 test_acc 0.7240479916536254
139 train_acc 0.4434360730593607 val_acc 0.47802197802197804 test_acc 0.7240479916536254
140 train_acc 0.4539212328767123 val_acc 0.5468864468864469 test_acc 0.7240479916536254
141 train_acc 0.4373401826484018 val_acc 0.4663003663003663 test_acc 0.7240479916536254
142 train_acc 0.47095034246575346 val_acc 0.5915750915750916 test_acc 0.7240479916536254
143 train_acc 0.4512300228310502 val_acc 0.5637362637362637 test_acc 0.7240479916536254
144 train_acc 0.45507134703196345 val_acc 0.5597069597069597 test_acc 0.7240479916536254
145 train_acc 0.4403082191780822 val_acc 0.4721611721611722 test_acc 0.7240479916536254
146 train_acc 0.4270433789954339 val_acc 0.5010989010989012 test_acc 0.7240479916536254
147 train_acc 0.4665125570776255 val_acc 0.484981684981685 test_acc 0.7240479916536254
148 train_acc 0.45414668949771686 val_acc 0.5413919413919414 test_acc 0.7240479916536254
149 train_acc 0.4288213470319635 val_acc 0.5274725274725275 test_acc 0.7240479916536254
150 train_acc 0.4702539954337899 val_acc 0.39999999999999997 test_acc 0.7240479916536254
151 train_acc 0.45603881278538805 val_acc 0.5556776556776557 test_acc 0.7240479916536254
152 train_acc 0.4425228310502283 val_acc 0.584981684981685 test_acc 0.7240479916536254
153 train_acc 0.4378481735159817 val_acc 0.47142857142857153 test_acc 0.7240479916536254
154 train_acc 0.45299657534246573 val_acc 0.5648351648351648 test_acc 0.7240479916536254
155 train_acc 0.44965182648401825 val_acc 0.478021978021978 test_acc 0.7240479916536254
156 train_acc 0.44490296803652973 val_acc 0.5926739926739927 test_acc 0.7240479916536254
157 train_acc 0.44114726027397266 val_acc 0.5835164835164836 test_acc 0.7240479916536254
158 train_acc 0.45704052511415527 val_acc 0.5652014652014652 test_acc 0.7240479916536254
159 train_acc 0.4412756849315068 val_acc 0.4655677655677656 test_acc 0.7240479916536254
160 train_acc 0.4636044520547945 val_acc 0.6186813186813187 test_acc 0.7240479916536254
161 train_acc 0.4457791095890411 val_acc 0.4285714285714286 test_acc 0.7240479916536254
162 train_acc 0.4632862442922374 val_acc 0.5827838827838828 test_acc 0.7240479916536254
163 train_acc 0.45248002283105015 val_acc 0.5857142857142857 test_acc 0.7240479916536254
164 train_acc 0.4577796803652968 val_acc 0.49743589743589745 test_acc 0.7240479916536254
165 train_acc 0.4630022831050229 val_acc 0.56996336996337 test_acc 0.7240479916536254
166 train_acc 0.4398972602739726 val_acc 0.45457875457875463 test_acc 0.7240479916536254
167 train_acc 0.4549771689497717 val_acc 0.5659340659340659 test_acc 0.7240479916536254
168 train_acc 0.4428481735159817 val_acc 0.48461538461538467 test_acc 0.7240479916536254
169 train_acc 0.44530536529680365 val_acc 0.4695970695970697 test_acc 0.7240479916536254
170 train_acc 0.44212614155251145 val_acc 0.5879120879120879 test_acc 0.7240479916536254
171 train_acc 0.45939640410958904 val_acc 0.49230769230769234 test_acc 0.7240479916536254
172 train_acc 0.449300799086758 val_acc 0.49853479853479854 test_acc 0.7240479916536254
173 train_acc 0.448029394977169 val_acc 0.5663003663003663 test_acc 0.7240479916536254
174 train_acc 0.445953196347032 val_acc 0.552014652014652 test_acc 0.7240479916536254
175 train_acc 0.446763698630137 val_acc 0.5956043956043956 test_acc 0.7240479916536254
176 train_acc 0.45190639269406396 val_acc 0.616117216117216 test_acc 0.7240479916536254
177 train_acc 0.44859303652968036 val_acc 0.49304029304029307 test_acc 0.7240479916536254
178 train_acc 0.4612100456621005 val_acc 0.5868131868131868 test_acc 0.7240479916536254
179 train_acc 0.4555136986301369 val_acc 0.6175824175824176 test_acc 0.7240479916536254
180 train_acc 0.4443236301369863 val_acc 0.6054945054945055 test_acc 0.7240479916536254
181 train_acc 0.45145833333333335 val_acc 0.5857142857142857 test_acc 0.7240479916536254
182 train_acc 0.4486786529680365 val_acc 0.5326007326007326 test_acc 0.7240479916536254
183 train_acc 0.46071061643835615 val_acc 0.5673992673992675 test_acc 0.7240479916536254
184 train_acc 0.46650399543378995 val_acc 0.5985347985347986 test_acc 0.7240479916536254
185 train_acc 0.4458361872146118 val_acc 0.5644688644688645 test_acc 0.7240479916536254
186 train_acc 0.4331392694063927 val_acc 0.49010989010989015 test_acc 0.7240479916536254
187 train_acc 0.437976598173516 val_acc 0.4926739926739927 test_acc 0.7240479916536254
188 train_acc 0.4628139269406393 val_acc 0.5717948717948718 test_acc 0.7240479916536254
189 train_acc 0.4460159817351598 val_acc 0.5029304029304029 test_acc 0.7240479916536254
190 train_acc 0.4538070776255707 val_acc 0.5787545787545788 test_acc 0.7240479916536254
191 train_acc 0.46224315068493155 val_acc 0.6062271062271063 test_acc 0.7240479916536254
192 train_acc 0.44549372146118715 val_acc 0.5967032967032967 test_acc 0.7240479916536254
193 train_acc 0.4405165525114155 val_acc 0.5670329670329671 test_acc 0.7240479916536254
194 train_acc 0.4625970319634704 val_acc 0.36630036630036633 test_acc 0.7240479916536254
195 train_acc 0.4735359589041096 val_acc 0.5318681318681319 test_acc 0.7240479916536254
196 train_acc 0.4609617579908676 val_acc 0.4626373626373627 test_acc 0.7240479916536254
197 train_acc 0.43659531963470316 val_acc 0.4989010989010989 test_acc 0.7240479916536254
198 train_acc 0.4557848173515982 val_acc 0.432967032967033 test_acc 0.7240479916536254
199 train_acc 0.4578110730593608 val_acc 0.4864468864468865 test_acc 0.7240479916536254
Finished training!
Best validation score: 0.6212454212454213
Test score: 0.7240479916536254
GCN_graph_UGTs(
  (convs): ModuleList(
    (0): Graphlevel_GCNConv(64, 64)
    (1): Graphlevel_GCNConv(64, 64)
    (2): Graphlevel_GCNConv(64, 64)
  )
  (atom_encoder): SLT_AtomEncoder(
    (atom_embedding_list): ModuleList(
      (0): Embedding(119, 64)
      (1): Embedding(5, 64)
      (2): Embedding(12, 64)
      (3): Embedding(12, 64)
      (4): Embedding(10, 64)
      (5): Embedding(6, 64)
      (6): Embedding(6, 64)
      (7): Embedding(2, 64)
      (8): Embedding(2, 64)
    )
    (weight_scores_list): ParameterList(
        (0): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (1): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (2): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (3): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (4): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (5): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (6): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (7): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (8): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
    )
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (graph_pred_linear): Linear(in_features=64, out_features=1, bias=True)
)
Name: convs.0.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.0.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.0.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.0.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.0.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.0.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.1.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.1.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.1.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.1.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.1.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.2.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.2.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.2.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.2.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.2.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.atom_embedding_list.0.weight, Shape: torch.Size([119, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.1.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.2.weight, Shape: torch.Size([12, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.3.weight, Shape: torch.Size([12, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.4.weight, Shape: torch.Size([10, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.5.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.6.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.7.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.8.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: atom_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.3, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.4, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.5, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.6, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.7, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.8, Shape: torch.Size([1, 64]), Requires Grad: True
Name: batch_norms.0.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.0.bias, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.1.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.1.bias, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.2.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.2.bias, Shape: torch.Size([64]), Requires Grad: True
Name: graph_pred_linear.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: graph_pred_linear.bias, Shape: torch.Size([1]), Requires Grad: True
/artic/h-ito/BingoGCN/__outputs__/Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molbace_Msup_L3_M16_S3125/dump..Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molbace_Msup_L3_M16_S3125.pth
0 train_acc 0.2941809360730594
1 train_acc 0.6074714611872146
2 train_acc 0.56988299086758
3 train_acc 0.5248630136986301
4 train_acc 0.4687928082191781
5 train_acc 0.4683304794520548
6 train_acc 0.44990582191780815
7 train_acc 0.4134503424657535
8 train_acc 0.42675513698630135
9 train_acc 0.4396718036529681
10 train_acc 0.41369720319634706
11 train_acc 0.41757134703196347
12 train_acc 0.42390696347031964
13 train_acc 0.42107876712328773
14 train_acc 0.4317622716894977
15 train_acc 0.41725456621004564
16 train_acc 0.425587899543379
17 train_acc 0.42503995433789954
18 train_acc 0.4046860730593608
19 train_acc 0.4145533675799087
20 train_acc 0.4108019406392694
21 train_acc 0.44550085616438356
22 train_acc 0.422796803652968
23 train_acc 0.424158105022831
24 train_acc 0.4302183219178082
25 train_acc 0.4255308219178082
26 train_acc 0.42999429223744295
27 train_acc 0.42192208904109585
28 train_acc 0.4347973744292238
29 train_acc 0.42669235159817354
30 train_acc 0.42925513698630136
31 train_acc 0.4174029680365297
32 train_acc 0.4213156392694064
33 train_acc 0.39828196347031963
34 train_acc 0.40448915525114154
35 train_acc 0.42433789954337897
36 train_acc 0.41310074200913244
37 train_acc 0.4278296232876712
38 train_acc 0.4261615296803653
39 train_acc 0.40687214611872147
40 train_acc 0.43325342465753425
41 train_acc 0.4303966894977169
42 train_acc 0.4366067351598174
43 train_acc 0.41343892694063933
44 train_acc 0.4118835616438356
45 train_acc 0.42755707762557077
46 train_acc 0.42229452054794514
47 train_acc 0.4213184931506849
48 train_acc 0.44040810502283106
49 train_acc 0.4340325342465753
50 train_acc 0.4278909817351598
51 train_acc 0.40912956621004565
52 train_acc 0.4369406392694064
53 train_acc 0.4164868721461187
54 train_acc 0.4378453196347032
55 train_acc 0.4312813926940639
56 train_acc 0.4409817351598173
57 train_acc 0.41878710045662104
58 train_acc 0.44316210045662097
59 train_acc 0.4357106164383562
60 train_acc 0.426917808219178
61 train_acc 0.4320576484018265
62 train_acc 0.427023401826484
63 train_acc 0.4469206621004566
64 train_acc 0.4274914383561644
65 train_acc 0.45877853881278535
66 train_acc 0.44733447488584477
67 train_acc 0.4309503424657534
68 train_acc 0.44037100456621003
69 train_acc 0.4359617579908676
70 train_acc 0.43676940639269407
71 train_acc 0.44212899543379003
72 train_acc 0.4523030821917808
73 train_acc 0.44497146118721465
74 train_acc 0.4605964611872146
75 train_acc 0.4353453196347032
76 train_acc 0.4259788812785388
77 train_acc 0.42678652968036535
78 train_acc 0.4412542808219178
79 train_acc 0.4475684931506849
80 train_acc 0.431837899543379
81 train_acc 0.43305650684931507
82 train_acc 0.43738869863013696
83 train_acc 0.42356164383561645
84 train_acc 0.4418978310502283
85 train_acc 0.455990296803653
86 train_acc 0.4528767123287671
87 train_acc 0.4521746575342465
88 train_acc 0.43681506849315066
89 train_acc 0.4537014840182648
90 train_acc 0.43605878995433794
91 train_acc 0.44821061643835614
92 train_acc 0.4485359589041096
93 train_acc 0.45415525114155253
94 train_acc 0.4629623287671233
95 train_acc 0.45537100456621005
96 train_acc 0.4601740867579909
97 train_acc 0.46180936073059364
98 train_acc 0.45738013698630137
99 train_acc 0.4458961187214612
100 train_acc 0.42628139269406395 val_acc 0.6043956043956044 test_acc 0.6870109546165885
101 train_acc 0.43627853881278544 val_acc 0.5142857142857142 test_acc 0.6870109546165885
102 train_acc 0.4619606164383562 val_acc 0.6010989010989011 test_acc 0.6870109546165885
103 train_acc 0.4630393835616438 val_acc 0.6062271062271063 test_acc 0.7252651712745608
104 train_acc 0.4638156392694064 val_acc 0.6157509157509158 test_acc 0.7285689445313858
105 train_acc 0.45966038812785387 val_acc 0.5758241758241759 test_acc 0.7285689445313858
106 train_acc 0.4451812214611872 val_acc 0.5941391941391942 test_acc 0.7285689445313858
107 train_acc 0.47315353881278543 val_acc 0.5717948717948719 test_acc 0.7285689445313858
108 train_acc 0.4718921232876713 val_acc 0.6413919413919414 test_acc 0.7285689445313858
109 train_acc 0.45886130136986303 val_acc 0.5827838827838828 test_acc 0.7285689445313858
110 train_acc 0.45933076484018265 val_acc 0.5923076923076923 test_acc 0.7285689445313858
111 train_acc 0.4584617579908676 val_acc 0.5695970695970696 test_acc 0.7285689445313858
112 train_acc 0.4575085616438356 val_acc 0.6293040293040294 test_acc 0.7285689445313858
113 train_acc 0.469962899543379 val_acc 0.5007326007326007 test_acc 0.7285689445313858
114 train_acc 0.45267979452054796 val_acc 0.6032967032967034 test_acc 0.7285689445313858
115 train_acc 0.4480022831050228 val_acc 0.595970695970696 test_acc 0.7285689445313858
116 train_acc 0.468972602739726 val_acc 0.5538461538461539 test_acc 0.7285689445313858
117 train_acc 0.4686272831050228 val_acc 0.580952380952381 test_acc 0.7285689445313858
118 train_acc 0.46001141552511415 val_acc 0.5681318681318681 test_acc 0.7285689445313858
119 train_acc 0.45234589041095896 val_acc 0.4611721611721612 test_acc 0.7285689445313858
120 train_acc 0.4722945205479452 val_acc 0.5802197802197802 test_acc 0.7285689445313858
121 train_acc 0.4511244292237443 val_acc 0.6135531135531136 test_acc 0.7285689445313858
122 train_acc 0.4683047945205479 val_acc 0.5780219780219781 test_acc 0.7285689445313858
123 train_acc 0.45065068493150684 val_acc 0.5912087912087912 test_acc 0.7285689445313858
124 train_acc 0.45826198630136983 val_acc 0.5904761904761905 test_acc 0.7285689445313858
125 train_acc 0.4590325342465753 val_acc 0.48681318681318686 test_acc 0.7285689445313858
126 train_acc 0.46726312785388135 val_acc 0.417948717948718 test_acc 0.7285689445313858
127 train_acc 0.44037100456621003 val_acc 0.5967032967032967 test_acc 0.7285689445313858
128 train_acc 0.46748858447488584 val_acc 0.5923076923076923 test_acc 0.7285689445313858
129 train_acc 0.4779252283105022 val_acc 0.5952380952380953 test_acc 0.7285689445313858
130 train_acc 0.45502283105022834 val_acc 0.594871794871795 test_acc 0.7285689445313858
131 train_acc 0.47779537671232875 val_acc 0.4190476190476191 test_acc 0.7285689445313858
132 train_acc 0.46250428082191786 val_acc 0.552014652014652 test_acc 0.7285689445313858
133 train_acc 0.4661272831050227 val_acc 0.584981684981685 test_acc 0.7285689445313858
134 train_acc 0.463601598173516 val_acc 0.5205128205128206 test_acc 0.7285689445313858
135 train_acc 0.4817522831050228 val_acc 0.5805860805860806 test_acc 0.7285689445313858
136 train_acc 0.4527454337899543 val_acc 0.5622710622710623 test_acc 0.7285689445313858
137 train_acc 0.47833047945205476 val_acc 0.4336996336996337 test_acc 0.7285689445313858
138 train_acc 0.47646118721461184 val_acc 0.6062271062271063 test_acc 0.7285689445313858
139 train_acc 0.4728167808219178 val_acc 0.4871794871794872 test_acc 0.7285689445313858
140 train_acc 0.4451255707762557 val_acc 0.568864468864469 test_acc 0.7285689445313858
141 train_acc 0.45119292237442926 val_acc 0.5915750915750916 test_acc 0.7285689445313858
142 train_acc 0.4615696347031964 val_acc 0.5699633699633699 test_acc 0.7285689445313858
143 train_acc 0.4607505707762557 val_acc 0.4882783882783883 test_acc 0.7285689445313858
144 train_acc 0.46880993150684924 val_acc 0.5820512820512821 test_acc 0.7285689445313858
145 train_acc 0.45595319634703196 val_acc 0.6043956043956044 test_acc 0.7285689445313858
146 train_acc 0.4637243150684931 val_acc 0.535897435897436 test_acc 0.7285689445313858
147 train_acc 0.47753139269406397 val_acc 0.4926739926739927 test_acc 0.7285689445313858
148 train_acc 0.4620348173515982 val_acc 0.4245421245421246 test_acc 0.7285689445313858
149 train_acc 0.48261986301369864 val_acc 0.5871794871794872 test_acc 0.7285689445313858
150 train_acc 0.4667751141552511 val_acc 0.6102564102564103 test_acc 0.7285689445313858
151 train_acc 0.46359589041095894 val_acc 0.4945054945054945 test_acc 0.7285689445313858
152 train_acc 0.4613013698630137 val_acc 0.48608058608058613 test_acc 0.7285689445313858
153 train_acc 0.4735987442922374 val_acc 0.5501831501831502 test_acc 0.7285689445313858
154 train_acc 0.4581078767123288 val_acc 0.6256410256410256 test_acc 0.7285689445313858
155 train_acc 0.46150684931506847 val_acc 0.48424908424908425 test_acc 0.7285689445313858
156 train_acc 0.4772788242009133 val_acc 0.5307692307692309 test_acc 0.7285689445313858
157 train_acc 0.48296232876712325 val_acc 0.5197802197802198 test_acc 0.7285689445313858
158 train_acc 0.4523373287671233 val_acc 0.5864468864468865 test_acc 0.7285689445313858
159 train_acc 0.4824001141552512 val_acc 0.5223443223443224 test_acc 0.7285689445313858
160 train_acc 0.48397260273972603 val_acc 0.5446886446886448 test_acc 0.7285689445313858
161 train_acc 0.4809446347031964 val_acc 0.5776556776556777 test_acc 0.7285689445313858
162 train_acc 0.4688855593607306 val_acc 0.5454212454212455 test_acc 0.7285689445313858
163 train_acc 0.4481164383561643 val_acc 0.6058608058608058 test_acc 0.7285689445313858
164 train_acc 0.4524029680365297 val_acc 0.5391941391941392 test_acc 0.7285689445313858
165 train_acc 0.45999714611872144 val_acc 0.5864468864468865 test_acc 0.7285689445313858
166 train_acc 0.47142123287671234 val_acc 0.5659340659340659 test_acc 0.7285689445313858
167 train_acc 0.462537100456621 val_acc 0.5443223443223444 test_acc 0.7285689445313858
168 train_acc 0.4832277397260273 val_acc 0.6 test_acc 0.7285689445313858
169 train_acc 0.4624857305936072 val_acc 0.5695970695970696 test_acc 0.7285689445313858
170 train_acc 0.4881506849315068 val_acc 0.5333333333333333 test_acc 0.7285689445313858
171 train_acc 0.49440353881278537 val_acc 0.5373626373626373 test_acc 0.7285689445313858
172 train_acc 0.47171803652968036 val_acc 0.5106227106227107 test_acc 0.7285689445313858
173 train_acc 0.47277968036529683 val_acc 0.5934065934065934 test_acc 0.7285689445313858
174 train_acc 0.47796803652968034 val_acc 0.5227106227106227 test_acc 0.7285689445313858
175 train_acc 0.48474029680365294 val_acc 0.5494505494505495 test_acc 0.7285689445313858
176 train_acc 0.48208047945205484 val_acc 0.506959706959707 test_acc 0.7285689445313858
177 train_acc 0.4850285388127854 val_acc 0.5978021978021978 test_acc 0.7285689445313858
178 train_acc 0.48078196347031965 val_acc 0.5366300366300367 test_acc 0.7285689445313858
179 train_acc 0.4742808219178082 val_acc 0.4776556776556777 test_acc 0.7285689445313858
180 train_acc 0.49763413242009136 val_acc 0.558974358974359 test_acc 0.7285689445313858
181 train_acc 0.47467180365296807 val_acc 0.5494505494505495 test_acc 0.7285689445313858
182 train_acc 0.487044805936073 val_acc 0.5787545787545787 test_acc 0.7285689445313858
183 train_acc 0.4879366438356165 val_acc 0.6 test_acc 0.7285689445313858
184 train_acc 0.5046118721461187 val_acc 0.5597069597069597 test_acc 0.7285689445313858
185 train_acc 0.4789925799086759 val_acc 0.48498168498168504 test_acc 0.7285689445313858
186 train_acc 0.47850171232876715 val_acc 0.6417582417582417 test_acc 0.7285689445313858
187 train_acc 0.48070490867579907 val_acc 0.5054945054945056 test_acc 0.7285689445313858
188 train_acc 0.4789583333333333 val_acc 0.63992673992674 test_acc 0.7527386541471048
189 train_acc 0.4794292237442922 val_acc 0.48058608058608066 test_acc 0.7527386541471048
190 train_acc 0.4982049086757991 val_acc 0.5798534798534799 test_acc 0.7527386541471048
191 train_acc 0.49218036529680365 val_acc 0.5692307692307692 test_acc 0.7527386541471048
192 train_acc 0.4808418949771689 val_acc 0.5989010989010989 test_acc 0.7527386541471048
193 train_acc 0.4768236301369863 val_acc 0.5853479853479854 test_acc 0.7527386541471048
194 train_acc 0.44160388127853883 val_acc 0.5212454212454213 test_acc 0.7527386541471048
195 train_acc 0.4769406392694064 val_acc 0.6194139194139194 test_acc 0.7527386541471048
196 train_acc 0.45200627853881276 val_acc 0.4058608058608059 test_acc 0.7527386541471048
197 train_acc 0.4758561643835616 val_acc 0.5750915750915752 test_acc 0.7527386541471048
198 train_acc 0.48710616438356164 val_acc 0.3981684981684982 test_acc 0.7527386541471048
199 train_acc 0.47661244292237437 val_acc 0.4461538461538461 test_acc 0.7527386541471048
Finished training!
Best validation score: 0.63992673992674
Test score: 0.7527386541471048
GCN_graph_UGTs(
  (convs): ModuleList(
    (0): Graphlevel_GCNConv(64, 64)
    (1): Graphlevel_GCNConv(64, 64)
    (2): Graphlevel_GCNConv(64, 64)
  )
  (atom_encoder): SLT_AtomEncoder(
    (atom_embedding_list): ModuleList(
      (0): Embedding(119, 64)
      (1): Embedding(5, 64)
      (2): Embedding(12, 64)
      (3): Embedding(12, 64)
      (4): Embedding(10, 64)
      (5): Embedding(6, 64)
      (6): Embedding(6, 64)
      (7): Embedding(2, 64)
      (8): Embedding(2, 64)
    )
    (weight_scores_list): ParameterList(
        (0): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (1): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (2): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (3): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (4): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (5): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (6): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (7): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (8): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
    )
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (graph_pred_linear): Linear(in_features=64, out_features=1, bias=True)
)
Name: convs.0.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.0.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.0.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.0.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.0.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.0.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.1.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.1.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.1.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.1.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.1.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.2.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.2.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.2.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.2.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.2.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.atom_embedding_list.0.weight, Shape: torch.Size([119, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.1.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.2.weight, Shape: torch.Size([12, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.3.weight, Shape: torch.Size([12, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.4.weight, Shape: torch.Size([10, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.5.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.6.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.7.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.8.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: atom_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.3, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.4, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.5, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.6, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.7, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.8, Shape: torch.Size([1, 64]), Requires Grad: True
Name: batch_norms.0.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.0.bias, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.1.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.1.bias, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.2.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.2.bias, Shape: torch.Size([64]), Requires Grad: True
Name: graph_pred_linear.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: graph_pred_linear.bias, Shape: torch.Size([1]), Requires Grad: True
/artic/h-ito/BingoGCN/__outputs__/Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molbace_Msup_L3_M16_S3125/dump..Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molbace_Msup_L3_M16_S3125.pth
0 train_acc 0.22000856164383562
1 train_acc 0.5656549657534247
2 train_acc 0.5285359589041095
3 train_acc 0.4934988584474886
4 train_acc 0.45897545662100453
5 train_acc 0.43844463470319633
6 train_acc 0.4493122146118722
7 train_acc 0.44408105022831046
8 train_acc 0.44390410958904114
9 train_acc 0.46646261415525114
10 train_acc 0.42642694063926945
11 train_acc 0.43538812785388126
12 train_acc 0.4148316210045662
13 train_acc 0.4352853881278539
14 train_acc 0.4352939497716895
15 train_acc 0.41299372146118724
16 train_acc 0.3988227739726028
17 train_acc 0.43435359589041095
18 train_acc 0.4214269406392694
19 train_acc 0.4230079908675799
20 train_acc 0.4256478310502283
21 train_acc 0.3985958904109589
22 train_acc 0.4063712899543379
23 train_acc 0.4193778538812785
24 train_acc 0.4003881278538812
25 train_acc 0.4105636415525114
26 train_acc 0.4245148401826484
27 train_acc 0.4088955479452055
28 train_acc 0.41460045662100453
29 train_acc 0.41811786529680367
30 train_acc 0.4169520547945205
31 train_acc 0.4231292808219178
32 train_acc 0.41471175799086757
33 train_acc 0.4216038812785388
34 train_acc 0.410704908675799
35 train_acc 0.4220148401826484
36 train_acc 0.38904965753424664
37 train_acc 0.3895662100456621
38 train_acc 0.3970262557077625
39 train_acc 0.40419235159817357
40 train_acc 0.407240296803653
41 train_acc 0.37748858447488587
42 train_acc 0.3976341324200913
43 train_acc 0.399115296803653
44 train_acc 0.3897374429223744
45 train_acc 0.38100456621004564
46 train_acc 0.3854951484018265
47 train_acc 0.39101883561643835
48 train_acc 0.4130565068493151
49 train_acc 0.40081621004566215
50 train_acc 0.41305365296803653
51 train_acc 0.41106735159817354
52 train_acc 0.41670947488584476
53 train_acc 0.41784531963470317
54 train_acc 0.4375513698630137
55 train_acc 0.40500856164383553
56 train_acc 0.408533105022831
57 train_acc 0.4326455479452055
58 train_acc 0.4190382420091324
59 train_acc 0.4220376712328767
60 train_acc 0.3955593607305936
61 train_acc 0.40200627853881277
62 train_acc 0.42327910958904114
63 train_acc 0.40009988584474887
64 train_acc 0.41378424657534246
65 train_acc 0.43091609589041097
66 train_acc 0.4253025114155251
67 train_acc 0.4289297945205479
68 train_acc 0.4186472602739726
69 train_acc 0.4243521689497717
70 train_acc 0.43591894977168955
71 train_acc 0.42074771689497714
72 train_acc 0.4359788812785388
73 train_acc 0.43265981735159814
74 train_acc 0.4363841324200914
75 train_acc 0.4258247716894977
76 train_acc 0.43080194063926935
77 train_acc 0.4481478310502283
78 train_acc 0.42577625570776256
79 train_acc 0.413019406392694
80 train_acc 0.42593321917808213
81 train_acc 0.433347602739726
82 train_acc 0.41972317351598165
83 train_acc 0.42381278538812794
84 train_acc 0.4249857305936073
85 train_acc 0.422023401826484
86 train_acc 0.4347117579908676
87 train_acc 0.4280936073059361
88 train_acc 0.41773116438356167
89 train_acc 0.4443493150684932
90 train_acc 0.4165211187214612
91 train_acc 0.4244092465753425
92 train_acc 0.40691210045662096
93 train_acc 0.41852168949771684
94 train_acc 0.42251855022831053
95 train_acc 0.43721461187214616
96 train_acc 0.40607591324200915
97 train_acc 0.4529366438356164
98 train_acc 0.4297945205479452
99 train_acc 0.4377825342465753
100 train_acc 0.43117579908675796 val_acc 0.541025641025641 test_acc 0.6943140323422013
101 train_acc 0.44221175799086754 val_acc 0.5725274725274725 test_acc 0.6943140323422013
102 train_acc 0.4497374429223744 val_acc 0.6098901098901099 test_acc 0.7059641801425839
103 train_acc 0.45138698630136986 val_acc 0.5168498168498169 test_acc 0.7059641801425839
104 train_acc 0.4323030821917808 val_acc 0.5835164835164836 test_acc 0.7059641801425839
105 train_acc 0.4211244292237443 val_acc 0.5021978021978023 test_acc 0.7059641801425839
106 train_acc 0.4208361872146118 val_acc 0.5655677655677656 test_acc 0.7059641801425839
107 train_acc 0.4249001141552512 val_acc 0.5069597069597069 test_acc 0.7059641801425839
108 train_acc 0.44459189497716894 val_acc 0.5263736263736264 test_acc 0.7059641801425839
109 train_acc 0.4267351598173516 val_acc 0.5241758241758242 test_acc 0.7059641801425839
110 train_acc 0.4499229452054795 val_acc 0.5578754578754579 test_acc 0.7059641801425839
111 train_acc 0.44431506849315067 val_acc 0.554945054945055 test_acc 0.7059641801425839
112 train_acc 0.4259960045662101 val_acc 0.5142857142857142 test_acc 0.7059641801425839
113 train_acc 0.4504138127853881 val_acc 0.5593406593406594 test_acc 0.7059641801425839
114 train_acc 0.44693635844748864 val_acc 0.5849816849816849 test_acc 0.7059641801425839
115 train_acc 0.46053224885844746 val_acc 0.5340659340659342 test_acc 0.7059641801425839
116 train_acc 0.43410388127853883 val_acc 0.5249084249084249 test_acc 0.7059641801425839
117 train_acc 0.452060502283105 val_acc 0.5241758241758242 test_acc 0.7059641801425839
118 train_acc 0.44750000000000006 val_acc 0.5443223443223444 test_acc 0.7059641801425839
119 train_acc 0.4178110730593607 val_acc 0.4706959706959707 test_acc 0.7059641801425839
120 train_acc 0.468892694063927 val_acc 0.5564102564102564 test_acc 0.7059641801425839
121 train_acc 0.45250285388127853 val_acc 0.5234432234432235 test_acc 0.7059641801425839
122 train_acc 0.4407990867579909 val_acc 0.49633699633699635 test_acc 0.7059641801425839
123 train_acc 0.4567537100456621 val_acc 0.5743589743589744 test_acc 0.7059641801425839
124 train_acc 0.44628710045662096 val_acc 0.595970695970696 test_acc 0.7059641801425839
125 train_acc 0.45468036529680367 val_acc 0.5106227106227106 test_acc 0.7059641801425839
126 train_acc 0.4593093607305936 val_acc 0.5886446886446886 test_acc 0.7059641801425839
127 train_acc 0.46790525114155246 val_acc 0.5622710622710623 test_acc 0.7059641801425839
128 train_acc 0.45888984018264845 val_acc 0.5838827838827839 test_acc 0.7059641801425839
129 train_acc 0.4518792808219178 val_acc 0.4131868131868132 test_acc 0.7059641801425839
130 train_acc 0.4683033675799087 val_acc 0.5271062271062271 test_acc 0.7059641801425839
131 train_acc 0.4688470319634702 val_acc 0.48901098901098905 test_acc 0.7059641801425839
132 train_acc 0.44161244292237445 val_acc 0.5743589743589744 test_acc 0.7059641801425839
133 train_acc 0.46547231735159816 val_acc 0.5494505494505494 test_acc 0.7059641801425839
134 train_acc 0.48394121004566215 val_acc 0.558974358974359 test_acc 0.7059641801425839
135 train_acc 0.4512328767123288 val_acc 0.5835164835164836 test_acc 0.7059641801425839
136 train_acc 0.4089840182648402 val_acc 0.5271062271062271 test_acc 0.7059641801425839
137 train_acc 0.42850599315068494 val_acc 0.5575091575091575 test_acc 0.7059641801425839
138 train_acc 0.47641267123287667 val_acc 0.5721611721611721 test_acc 0.7059641801425839
139 train_acc 0.43327910958904114 val_acc 0.5538461538461539 test_acc 0.7059641801425839
140 train_acc 0.46314497716894987 val_acc 0.6336996336996338 test_acc 0.7184837419579204
141 train_acc 0.46093321917808217 val_acc 0.5736263736263737 test_acc 0.7184837419579204
142 train_acc 0.4510901826484018 val_acc 0.5934065934065934 test_acc 0.7184837419579204
143 train_acc 0.44815924657534245 val_acc 0.6043956043956044 test_acc 0.7184837419579204
144 train_acc 0.4528196347031964 val_acc 0.5677655677655677 test_acc 0.7184837419579204
145 train_acc 0.45597888127853886 val_acc 0.552014652014652 test_acc 0.7184837419579204
146 train_acc 0.4343707191780822 val_acc 0.563003663003663 test_acc 0.7184837419579204
147 train_acc 0.4695690639269407 val_acc 0.49963369963369964 test_acc 0.7184837419579204
148 train_acc 0.44572203196347027 val_acc 0.5695970695970696 test_acc 0.7184837419579204
149 train_acc 0.4622973744292237 val_acc 0.5761904761904763 test_acc 0.7184837419579204
150 train_acc 0.44019977168949775 val_acc 0.6047619047619048 test_acc 0.7184837419579204
151 train_acc 0.44175371004566205 val_acc 0.5666666666666667 test_acc 0.7184837419579204
152 train_acc 0.45675941780821916 val_acc 0.47728937728937737 test_acc 0.7184837419579204
153 train_acc 0.4347831050228311 val_acc 0.5117216117216117 test_acc 0.7184837419579204
154 train_acc 0.432023401826484 val_acc 0.49230769230769234 test_acc 0.7184837419579204
155 train_acc 0.46341181506849327 val_acc 0.5567765567765568 test_acc 0.7184837419579204
156 train_acc 0.44556792237442927 val_acc 0.5487179487179487 test_acc 0.7184837419579204
157 train_acc 0.44081621004566207 val_acc 0.5652014652014652 test_acc 0.7184837419579204
158 train_acc 0.4604880136986302 val_acc 0.5681318681318682 test_acc 0.7184837419579204
159 train_acc 0.463458904109589 val_acc 0.547985347985348 test_acc 0.7184837419579204
160 train_acc 0.47993436073059365 val_acc 0.4175824175824176 test_acc 0.7184837419579204
161 train_acc 0.4505650684931507 val_acc 0.5673992673992675 test_acc 0.7184837419579204
162 train_acc 0.41942922374429226 val_acc 0.5703296703296703 test_acc 0.7184837419579204
163 train_acc 0.4437942351598174 val_acc 0.4622710622710623 test_acc 0.7184837419579204
164 train_acc 0.44694920091324203 val_acc 0.5912087912087912 test_acc 0.7184837419579204
165 train_acc 0.4474600456621005 val_acc 0.5483516483516484 test_acc 0.7184837419579204
166 train_acc 0.4616752283105023 val_acc 0.4970695970695971 test_acc 0.7184837419579204
167 train_acc 0.4726683789954338 val_acc 0.42124542124542125 test_acc 0.7184837419579204
168 train_acc 0.4591866438356164 val_acc 0.5739926739926741 test_acc 0.7184837419579204
169 train_acc 0.4757705479452055 val_acc 0.6124542124542125 test_acc 0.7184837419579204
170 train_acc 0.48563498858447485 val_acc 0.5457875457875458 test_acc 0.7184837419579204
171 train_acc 0.4702425799086758 val_acc 0.5820512820512821 test_acc 0.7184837419579204
172 train_acc 0.47765125570776257 val_acc 0.46776556776556777 test_acc 0.7184837419579204
173 train_acc 0.44809075342465754 val_acc 0.5648351648351648 test_acc 0.7184837419579204
174 train_acc 0.44202340182648403 val_acc 0.5853479853479854 test_acc 0.7184837419579204
175 train_acc 0.4584474885844749 val_acc 0.5963369963369964 test_acc 0.7184837419579204
176 train_acc 0.4525542237442922 val_acc 0.6065934065934067 test_acc 0.7184837419579204
177 train_acc 0.473013698630137 val_acc 0.575091575091575 test_acc 0.7184837419579204
178 train_acc 0.47355593607305935 val_acc 0.49340659340659343 test_acc 0.7184837419579204
179 train_acc 0.44965182648401825 val_acc 0.5597069597069597 test_acc 0.7184837419579204
180 train_acc 0.4673487442922375 val_acc 0.5663003663003663 test_acc 0.7184837419579204
181 train_acc 0.4545547945205479 val_acc 0.5311355311355312 test_acc 0.7184837419579204
182 train_acc 0.4529109589041096 val_acc 0.6076923076923076 test_acc 0.7184837419579204
183 train_acc 0.45031963470319636 val_acc 0.6267399267399267 test_acc 0.7184837419579204
184 train_acc 0.47846746575342464 val_acc 0.5560439560439561 test_acc 0.7184837419579204
185 train_acc 0.45579337899543376 val_acc 0.5340659340659341 test_acc 0.7184837419579204
186 train_acc 0.43876141552511416 val_acc 0.5315018315018315 test_acc 0.7184837419579204
187 train_acc 0.4465482305936073 val_acc 0.6095238095238096 test_acc 0.7184837419579204
188 train_acc 0.4630051369863014 val_acc 0.44578754578754587 test_acc 0.7184837419579204
189 train_acc 0.4423116438356165 val_acc 0.6201465201465202 test_acc 0.7184837419579204
190 train_acc 0.45500285388127854 val_acc 0.6091575091575092 test_acc 0.7184837419579204
191 train_acc 0.4676455479452055 val_acc 0.5992673992673992 test_acc 0.7184837419579204
192 train_acc 0.45773116438356165 val_acc 0.5717948717948718 test_acc 0.7184837419579204
193 train_acc 0.4611272831050228 val_acc 0.5824175824175825 test_acc 0.7184837419579204
194 train_acc 0.43665239726027394 val_acc 0.5904761904761905 test_acc 0.7184837419579204
195 train_acc 0.47349600456621005 val_acc 0.5245421245421246 test_acc 0.7184837419579204
196 train_acc 0.47739440639269404 val_acc 0.6051282051282051 test_acc 0.7184837419579204
197 train_acc 0.4547488584474886 val_acc 0.5274725274725275 test_acc 0.7184837419579204
198 train_acc 0.46723458904109594 val_acc 0.615018315018315 test_acc 0.7184837419579204
199 train_acc 0.44275970319634705 val_acc 0.5783882783882784 test_acc 0.7184837419579204
Finished training!
Best validation score: 0.6336996336996338
Test score: 0.7184837419579204
acc mean: 0.7317567959195502  acc std: 0.015009308215902536 ece mean: 0.0 ece std 0.0
End time: 2025-03-28 22:53:38
Duration: 0:13:40.329754
