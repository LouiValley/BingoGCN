Start time: 2025-03-28 22:32:34
Namespace(num_layers=3, epochs=200, dim_hidden=64, repeat_times=3, linear_sparsity=0.1875, train_mode='score_only', rerand_freq=0, exp_name='Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molbace_Msup_L3_M16_S1875', weight_l1=0.0, sampling=None, samplingtype=None, sparse_decay=True, attack=None, auroc=False, attack_eps=0, dataset='ogbg-molbace', random_seed=None, resume=False, cuda=True, type_model='GCN_graph_UGTs', dropout=0.0, lr=0.01, weight_decay=0.0005, transductive=True, activation='relu', type_norm='batch', command='train', force_restart=False, seed_by_time=True, print_train_loss=False, num_gpus=1, output_dir='__outputs__', sync_dir='__sync__', save_best_model=True, optimizer='Adam', scheduler='CustomCosineLR', warm_epochs=0, finetuning_epochs=0, finetuning_lr=None, lr_milestones=[900, 1000, 1100], checkpoint_epochs=[], multisteplr_gamma=0.1, learning_framework='GraphLevelLearning', bn_track_running_stats=True, bn_affine=True, bn_momentum=0.1, init_mode='xor16_offset', init_mode_mask='kaiming_uniform', init_mode_linear=None, init_scale=1.0, init_scale_score=1.0, heads=1, sparsity_list=[0.1875, 0.458333, 0.729167], num_mask=3, enable_mask=True, enable_abs_comp=True, validate=False, pretrained_path=None, prunedw_path=None, enable_sw_mm=False, BN_GIN=False, evatime=False, drawadj=False, evanum=50, METIS=False, spadj=False, adjsparsity_ratio=0.0, enable_feat_pruning=False, featsparsity_ratio=0.0, enable_node_pruning=False, x_pruning_layer=0, regular_weight_pruning=None, num_of_weight_blocks=1, global_th_for_rowbyrow=False, download_prunedw=False, gra_part=False, no_edge_weight=False, sparse_tensor=False, original_edge_weight=False, only_train_data=False, flowgnn_debug=False, nmsparsity=True, M=16, unstructured_for_last_layer=False, xor_seed_using_instance_number=False, outgoing_centroids=False, folded_layer=0, BN_track_running_stats=True, folded_SM=False, half_folded=False, batch_size=64, elastic_net=False, elastic_lambda=5e-08, l1_ratio=0.5, no_norm=False, adp=False, SLT_Bonder=False, SLTAtom=True, SLTBond=True, SLTRoot=False, SLTAtom_ini='xor16_atom', SLTBond_ini='xor16_bond', SLTRoot_ini='default', dense_for_last_layer=True, local_pruning=False, local_sparsity_list=None, inference_time=False, sparsity_profiling=False, nm_decay=0.0001, num_feats=9, num_classes=2)
GCN_graph_UGTs(
  (convs): ModuleList(
    (0): Graphlevel_GCNConv(64, 64)
    (1): Graphlevel_GCNConv(64, 64)
    (2): Graphlevel_GCNConv(64, 64)
  )
  (atom_encoder): SLT_AtomEncoder(
    (atom_embedding_list): ModuleList(
      (0): Embedding(119, 64)
      (1): Embedding(5, 64)
      (2): Embedding(12, 64)
      (3): Embedding(12, 64)
      (4): Embedding(10, 64)
      (5): Embedding(6, 64)
      (6): Embedding(6, 64)
      (7): Embedding(2, 64)
      (8): Embedding(2, 64)
    )
    (weight_scores_list): ParameterList(
        (0): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (1): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (2): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (3): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (4): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (5): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (6): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (7): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (8): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
    )
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (graph_pred_linear): Linear(in_features=64, out_features=1, bias=True)
)
Name: convs.0.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.0.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.0.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.0.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.0.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.0.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.1.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.1.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.1.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.1.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.1.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.2.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.2.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.2.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.2.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.2.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.atom_embedding_list.0.weight, Shape: torch.Size([119, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.1.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.2.weight, Shape: torch.Size([12, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.3.weight, Shape: torch.Size([12, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.4.weight, Shape: torch.Size([10, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.5.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.6.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.7.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.8.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: atom_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.3, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.4, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.5, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.6, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.7, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.8, Shape: torch.Size([1, 64]), Requires Grad: True
Name: batch_norms.0.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.0.bias, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.1.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.1.bias, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.2.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.2.bias, Shape: torch.Size([64]), Requires Grad: True
Name: graph_pred_linear.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: graph_pred_linear.bias, Shape: torch.Size([1]), Requires Grad: True
/artic/h-ito/BingoGCN/__outputs__/Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molbace_Msup_L3_M16_S1875/dump..Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molbace_Msup_L3_M16_S1875.pth
0 train_acc 0.26313641552511413
1 train_acc 0.5999414954337899
2 train_acc 0.5708390410958905
3 train_acc 0.5235530821917809
4 train_acc 0.4799286529680365
5 train_acc 0.42986586757990874
6 train_acc 0.4490881849315068
7 train_acc 0.42668378995433787
8 train_acc 0.43145262557077624
9 train_acc 0.4423030821917808
10 train_acc 0.4387100456621004
11 train_acc 0.4573801369863013
12 train_acc 0.428548801369863
13 train_acc 0.43346175799086756
14 train_acc 0.4299486301369863
15 train_acc 0.4334717465753425
16 train_acc 0.44084760273972606
17 train_acc 0.4488869863013698
18 train_acc 0.4150142694063927
19 train_acc 0.41202340182648406
20 train_acc 0.4308190639269406
21 train_acc 0.42257420091324194
22 train_acc 0.42756278538812786
23 train_acc 0.4403595890410959
24 train_acc 0.4345833333333333
25 train_acc 0.444634703196347
26 train_acc 0.42474172374429225
27 train_acc 0.4433946917808219
28 train_acc 0.4221946347031963
29 train_acc 0.44559931506849315
30 train_acc 0.4165125570776256
31 train_acc 0.43971746575342463
32 train_acc 0.43893835616438354
33 train_acc 0.42648544520547943
34 train_acc 0.44201769406392694
35 train_acc 0.4161786529680366
36 train_acc 0.4303567351598173
37 train_acc 0.42023972602739723
38 train_acc 0.4238199200913242
39 train_acc 0.4255165525114155
40 train_acc 0.4127910958904109
41 train_acc 0.4219791666666667
42 train_acc 0.42214326484018266
43 train_acc 0.43373287671232874
44 train_acc 0.4290510844748858
45 train_acc 0.42684360730593607
46 train_acc 0.4034617579908676
47 train_acc 0.4208761415525114
48 train_acc 0.4104337899543379
49 train_acc 0.41265696347031966
50 train_acc 0.40047517123287674
51 train_acc 0.4053995433789955
52 train_acc 0.42157391552511414
53 train_acc 0.39307933789954336
54 train_acc 0.4317950913242009
55 train_acc 0.41036244292237445
56 train_acc 0.41357591324200915
57 train_acc 0.4133276255707763
58 train_acc 0.40959189497716897
59 train_acc 0.4308162100456622
60 train_acc 0.4246033105022831
61 train_acc 0.4386729452054794
62 train_acc 0.42037100456621
63 train_acc 0.4335958904109589
64 train_acc 0.42568207762557075
65 train_acc 0.4486215753424658
66 train_acc 0.4252211757990868
67 train_acc 0.43537243150684934
68 train_acc 0.4166780821917808
69 train_acc 0.44466894977168947
70 train_acc 0.4467551369863013
71 train_acc 0.42989440639269405
72 train_acc 0.42777111872146123
73 train_acc 0.4404337899543379
74 train_acc 0.4452083333333333
75 train_acc 0.41706621004566213
76 train_acc 0.4400970319634704
77 train_acc 0.43178795662100455
78 train_acc 0.42046803652968034
79 train_acc 0.41738013698630144
80 train_acc 0.4483932648401826
81 train_acc 0.44564212328767117
82 train_acc 0.4572631278538813
83 train_acc 0.45314783105022827
84 train_acc 0.43975456621004566
85 train_acc 0.4636843607305936
86 train_acc 0.44582191780821917
87 train_acc 0.4323544520547945
88 train_acc 0.42507562785388125
89 train_acc 0.4384731735159817
90 train_acc 0.44475456621004567
91 train_acc 0.45269263698630147
92 train_acc 0.4388299086757991
93 train_acc 0.4349200913242009
94 train_acc 0.45600742009132417
95 train_acc 0.4589012557077626
96 train_acc 0.4558447488584476
97 train_acc 0.44238299086757993
98 train_acc 0.4394563356164384
99 train_acc 0.4561786529680365
100 train_acc 0.4288912671232876 val_acc 0.5758241758241758 test_acc 0.6777951660580769
101 train_acc 0.4431963470319635 val_acc 0.5809523809523809 test_acc 0.6777951660580769
102 train_acc 0.42104452054794517 val_acc 0.5494505494505495 test_acc 0.6777951660580769
103 train_acc 0.444591894977169 val_acc 0.5897435897435898 test_acc 0.7402190923317684
104 train_acc 0.4331820776255708 val_acc 0.5934065934065934 test_acc 0.7402190923317684
105 train_acc 0.44224457762557073 val_acc 0.5794871794871795 test_acc 0.7402190923317684
106 train_acc 0.43918949771689497 val_acc 0.5190476190476191 test_acc 0.7402190923317684
107 train_acc 0.4459061073059361 val_acc 0.5897435897435898 test_acc 0.7402190923317684
108 train_acc 0.43086757990867586 val_acc 0.5897435897435898 test_acc 0.7402190923317684
109 train_acc 0.4391267123287671 val_acc 0.5432234432234433 test_acc 0.7402190923317684
110 train_acc 0.4306763698630137 val_acc 0.4644688644688645 test_acc 0.7402190923317684
111 train_acc 0.44057077625570773 val_acc 0.4857142857142858 test_acc 0.7402190923317684
112 train_acc 0.4469349315068493 val_acc 0.5516483516483517 test_acc 0.7402190923317684
113 train_acc 0.4459560502283105 val_acc 0.5802197802197802 test_acc 0.7402190923317684
114 train_acc 0.4638156392694064 val_acc 0.5622710622710623 test_acc 0.7402190923317684
115 train_acc 0.4358076484018265 val_acc 0.6128205128205129 test_acc 0.7402190923317684
116 train_acc 0.44751712328767124 val_acc 0.5915750915750916 test_acc 0.7402190923317684
117 train_acc 0.47289240867579907 val_acc 0.575091575091575 test_acc 0.7402190923317684
118 train_acc 0.4592009132420092 val_acc 0.613919413919414 test_acc 0.7402190923317684
119 train_acc 0.44642979452054793 val_acc 0.5413919413919414 test_acc 0.7402190923317684
120 train_acc 0.4775199771689498 val_acc 0.589010989010989 test_acc 0.7402190923317684
121 train_acc 0.4558190639269406 val_acc 0.6227106227106227 test_acc 0.7402190923317684
122 train_acc 0.4685930365296804 val_acc 0.4908424908424909 test_acc 0.7402190923317684
123 train_acc 0.46555650684931504 val_acc 0.6545787545787546 test_acc 0.7402190923317684
124 train_acc 0.4403909817351598 val_acc 0.5901098901098901 test_acc 0.7454355764214919
125 train_acc 0.4502411529680365 val_acc 0.5150183150183151 test_acc 0.7454355764214919
126 train_acc 0.4733675799086758 val_acc 0.526007326007326 test_acc 0.7454355764214919
127 train_acc 0.45142979452054793 val_acc 0.621978021978022 test_acc 0.7454355764214919
128 train_acc 0.47978881278538815 val_acc 0.6095238095238096 test_acc 0.7454355764214919
129 train_acc 0.4524857305936073 val_acc 0.4871794871794872 test_acc 0.7454355764214919
130 train_acc 0.4669235159817352 val_acc 0.6311355311355311 test_acc 0.7454355764214919
131 train_acc 0.4566666666666666 val_acc 0.575091575091575 test_acc 0.7454355764214919
132 train_acc 0.4474571917808219 val_acc 0.5747252747252748 test_acc 0.7454355764214919
133 train_acc 0.4464868721461187 val_acc 0.558974358974359 test_acc 0.7454355764214919
134 train_acc 0.4540068493150685 val_acc 0.5615384615384615 test_acc 0.7454355764214919
135 train_acc 0.45291952054794515 val_acc 0.53992673992674 test_acc 0.7454355764214919
136 train_acc 0.4671632420091324 val_acc 0.593040293040293 test_acc 0.7454355764214919
137 train_acc 0.47640981735159815 val_acc 0.5249084249084248 test_acc 0.7454355764214919
138 train_acc 0.43960045662100455 val_acc 0.5626373626373626 test_acc 0.7454355764214919
139 train_acc 0.4783647260273973 val_acc 0.594871794871795 test_acc 0.7454355764214919
140 train_acc 0.46097602739726024 val_acc 0.5970695970695972 test_acc 0.7454355764214919
141 train_acc 0.45484018264840187 val_acc 0.6014652014652014 test_acc 0.7454355764214919
142 train_acc 0.47525399543379 val_acc 0.47765567765567774 test_acc 0.7454355764214919
143 train_acc 0.4772160388127854 val_acc 0.5274725274725275 test_acc 0.7454355764214919
144 train_acc 0.4824543378995433 val_acc 0.5875457875457876 test_acc 0.7454355764214919
145 train_acc 0.459412100456621 val_acc 0.5373626373626375 test_acc 0.7454355764214919
146 train_acc 0.4677882420091324 val_acc 0.5846153846153846 test_acc 0.7454355764214919
147 train_acc 0.458972602739726 val_acc 0.6329670329670329 test_acc 0.7454355764214919
148 train_acc 0.44357305936073055 val_acc 0.5164835164835165 test_acc 0.7454355764214919
149 train_acc 0.43625570776255707 val_acc 0.5465201465201466 test_acc 0.7454355764214919
150 train_acc 0.4124985730593608 val_acc 0.4000000000000001 test_acc 0.7454355764214919
151 train_acc 0.43966609589041095 val_acc 0.5732600732600732 test_acc 0.7454355764214919
152 train_acc 0.45202054794520546 val_acc 0.5146520146520146 test_acc 0.7454355764214919
153 train_acc 0.4115724885844749 val_acc 0.5454212454212455 test_acc 0.7454355764214919
154 train_acc 0.4307534246575343 val_acc 0.576923076923077 test_acc 0.7454355764214919
155 train_acc 0.4302368721461187 val_acc 0.5142857142857142 test_acc 0.7454355764214919
156 train_acc 0.4316609589041096 val_acc 0.528937728937729 test_acc 0.7454355764214919
157 train_acc 0.4368692922374429 val_acc 0.5538461538461539 test_acc 0.7454355764214919
158 train_acc 0.41521689497716896 val_acc 0.5468864468864469 test_acc 0.7454355764214919
159 train_acc 0.4275 val_acc 0.5725274725274725 test_acc 0.7454355764214919
160 train_acc 0.43720605022831055 val_acc 0.5619047619047619 test_acc 0.7454355764214919
161 train_acc 0.4486444063926941 val_acc 0.547985347985348 test_acc 0.7454355764214919
162 train_acc 0.45934075342465747 val_acc 0.5373626373626373 test_acc 0.7454355764214919
163 train_acc 0.45262557077625576 val_acc 0.5505494505494505 test_acc 0.7454355764214919
164 train_acc 0.45731592465753423 val_acc 0.5637362637362637 test_acc 0.7454355764214919
165 train_acc 0.43245148401826483 val_acc 0.5351648351648352 test_acc 0.7454355764214919
166 train_acc 0.4556563926940639 val_acc 0.5553113553113553 test_acc 0.7454355764214919
167 train_acc 0.4456392694063927 val_acc 0.5388278388278389 test_acc 0.7454355764214919
168 train_acc 0.4588156392694064 val_acc 0.5285714285714286 test_acc 0.7454355764214919
169 train_acc 0.46353025114155255 val_acc 0.526007326007326 test_acc 0.7454355764214919
170 train_acc 0.45491723744292234 val_acc 0.5542124542124542 test_acc 0.7454355764214919
171 train_acc 0.46801940639269407 val_acc 0.3816849816849817 test_acc 0.7454355764214919
172 train_acc 0.4453952625570776 val_acc 0.5450549450549451 test_acc 0.7454355764214919
173 train_acc 0.4740011415525114 val_acc 0.5241758241758242 test_acc 0.7454355764214919
174 train_acc 0.45162100456621 val_acc 0.4644688644688645 test_acc 0.7454355764214919
175 train_acc 0.4795348173515982 val_acc 0.4846153846153846 test_acc 0.7454355764214919
176 train_acc 0.4708675799086758 val_acc 0.5765567765567766 test_acc 0.7454355764214919
177 train_acc 0.4696432648401826 val_acc 0.5164835164835165 test_acc 0.7454355764214919
178 train_acc 0.4948373287671233 val_acc 0.5413919413919414 test_acc 0.7454355764214919
179 train_acc 0.47054223744292234 val_acc 0.5135531135531136 test_acc 0.7454355764214919
180 train_acc 0.47950057077625574 val_acc 0.4725274725274725 test_acc 0.7454355764214919
181 train_acc 0.47535388127853884 val_acc 0.44871794871794873 test_acc 0.7454355764214919
182 train_acc 0.4667465753424658 val_acc 0.5677655677655677 test_acc 0.7454355764214919
183 train_acc 0.47580194063926945 val_acc 0.5538461538461539 test_acc 0.7454355764214919
184 train_acc 0.4808761415525114 val_acc 0.4663003663003663 test_acc 0.7454355764214919
185 train_acc 0.47861015981735167 val_acc 0.5619047619047619 test_acc 0.7454355764214919
186 train_acc 0.4705222602739726 val_acc 0.4245421245421246 test_acc 0.7454355764214919
187 train_acc 0.47398401826484016 val_acc 0.5604395604395604 test_acc 0.7454355764214919
188 train_acc 0.4704823059360731 val_acc 0.42710622710622714 test_acc 0.7454355764214919
189 train_acc 0.4797317351598173 val_acc 0.41611721611721614 test_acc 0.7454355764214919
190 train_acc 0.48557648401826486 val_acc 0.5410256410256411 test_acc 0.7454355764214919
191 train_acc 0.4662985159817351 val_acc 0.3875457875457876 test_acc 0.7454355764214919
192 train_acc 0.4937728310502283 val_acc 0.4498168498168499 test_acc 0.7454355764214919
193 train_acc 0.4473116438356164 val_acc 0.4366300366300367 test_acc 0.7454355764214919
194 train_acc 0.4780165525114155 val_acc 0.4494505494505495 test_acc 0.7454355764214919
195 train_acc 0.48932648401826484 val_acc 0.5282051282051282 test_acc 0.7454355764214919
196 train_acc 0.4772745433789954 val_acc 0.5424908424908425 test_acc 0.7454355764214919
197 train_acc 0.479888698630137 val_acc 0.4882783882783883 test_acc 0.7454355764214919
198 train_acc 0.4935102739726027 val_acc 0.46373626373626375 test_acc 0.7454355764214919
199 train_acc 0.47662956621004565 val_acc 0.5717948717948718 test_acc 0.7454355764214919
Finished training!
Best validation score: 0.5901098901098901
Test score: 0.7454355764214919
GCN_graph_UGTs(
  (convs): ModuleList(
    (0): Graphlevel_GCNConv(64, 64)
    (1): Graphlevel_GCNConv(64, 64)
    (2): Graphlevel_GCNConv(64, 64)
  )
  (atom_encoder): SLT_AtomEncoder(
    (atom_embedding_list): ModuleList(
      (0): Embedding(119, 64)
      (1): Embedding(5, 64)
      (2): Embedding(12, 64)
      (3): Embedding(12, 64)
      (4): Embedding(10, 64)
      (5): Embedding(6, 64)
      (6): Embedding(6, 64)
      (7): Embedding(2, 64)
      (8): Embedding(2, 64)
    )
    (weight_scores_list): ParameterList(
        (0): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (1): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (2): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (3): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (4): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (5): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (6): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (7): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (8): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
    )
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (graph_pred_linear): Linear(in_features=64, out_features=1, bias=True)
)
Name: convs.0.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.0.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.0.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.0.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.0.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.0.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.1.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.1.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.1.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.1.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.1.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.2.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.2.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.2.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.2.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.2.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.atom_embedding_list.0.weight, Shape: torch.Size([119, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.1.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.2.weight, Shape: torch.Size([12, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.3.weight, Shape: torch.Size([12, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.4.weight, Shape: torch.Size([10, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.5.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.6.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.7.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.8.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: atom_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.3, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.4, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.5, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.6, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.7, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.8, Shape: torch.Size([1, 64]), Requires Grad: True
Name: batch_norms.0.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.0.bias, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.1.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.1.bias, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.2.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.2.bias, Shape: torch.Size([64]), Requires Grad: True
Name: graph_pred_linear.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: graph_pred_linear.bias, Shape: torch.Size([1]), Requires Grad: True
/artic/h-ito/BingoGCN/__outputs__/Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molbace_Msup_L3_M16_S1875/dump..Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molbace_Msup_L3_M16_S1875.pth
0 train_acc 0.29073772831050226
1 train_acc 0.6053082191780822
2 train_acc 0.552908105022831
3 train_acc 0.5271147260273973
4 train_acc 0.48434931506849316
5 train_acc 0.4682819634703196
6 train_acc 0.44095747716894973
7 train_acc 0.46136986301369864
8 train_acc 0.4247574200913242
9 train_acc 0.4346318493150685
10 train_acc 0.44399828767123295
11 train_acc 0.4252397260273973
12 train_acc 0.4310074200913242
13 train_acc 0.436398401826484
14 train_acc 0.4247317351598173
15 train_acc 0.4423915525114155
16 train_acc 0.4340011415525114
17 train_acc 0.3966267123287672
18 train_acc 0.44015696347031963
19 train_acc 0.43657534246575347
20 train_acc 0.4277111872146119
21 train_acc 0.43731735159817353
22 train_acc 0.4296632420091324
23 train_acc 0.4276683789954338
24 train_acc 0.4176398401826484
25 train_acc 0.44525399543378996
26 train_acc 0.4129708904109589
27 train_acc 0.4369577625570776
28 train_acc 0.4322460045662101
29 train_acc 0.4447759703196348
30 train_acc 0.4204337899543379
31 train_acc 0.4329623287671233
32 train_acc 0.42166952054794526
33 train_acc 0.4150856164383562
34 train_acc 0.44711757990867584
35 train_acc 0.4429138127853881
36 train_acc 0.44085759132420094
37 train_acc 0.41718607305936073
38 train_acc 0.4437785388127854
39 train_acc 0.4143093607305936
40 train_acc 0.42363869863013703
41 train_acc 0.43192066210045665
42 train_acc 0.42705479452054795
43 train_acc 0.43327340182648405
44 train_acc 0.4349143835616438
45 train_acc 0.4382091894977169
46 train_acc 0.4452482876712328
47 train_acc 0.4379166666666667
48 train_acc 0.4397231735159817
49 train_acc 0.45222317351598174
50 train_acc 0.43091038812785387
51 train_acc 0.4056135844748859
52 train_acc 0.435365296803653
53 train_acc 0.3993321917808219
54 train_acc 0.4313099315068493
55 train_acc 0.428765696347032
56 train_acc 0.43218892694063926
57 train_acc 0.43514554794520555
58 train_acc 0.4363042237442923
59 train_acc 0.44781678082191784
60 train_acc 0.44784817351598166
61 train_acc 0.4395776255707763
62 train_acc 0.4373715753424658
63 train_acc 0.43504566210045664
64 train_acc 0.42934931506849316
65 train_acc 0.44453196347031965
66 train_acc 0.4514383561643836
67 train_acc 0.44733162100456625
68 train_acc 0.45321632420091323
69 train_acc 0.45585901826484015
70 train_acc 0.43464183789954336
71 train_acc 0.45269406392694067
72 train_acc 0.4432049086757991
73 train_acc 0.45667094748858444
74 train_acc 0.4267066210045662
75 train_acc 0.4615382420091324
76 train_acc 0.4544634703196347
77 train_acc 0.44469463470319637
78 train_acc 0.45696061643835617
79 train_acc 0.46358162100456624
80 train_acc 0.4411101598173516
81 train_acc 0.4574600456621004
82 train_acc 0.4587357305936073
83 train_acc 0.46091894977168946
84 train_acc 0.46025399543379
85 train_acc 0.4504223744292237
86 train_acc 0.4640054223744292
87 train_acc 0.46122716894977167
88 train_acc 0.4534874429223744
89 train_acc 0.4549514840182648
90 train_acc 0.4600256849315069
91 train_acc 0.45511986301369867
92 train_acc 0.46011700913242004
93 train_acc 0.46301084474885845
94 train_acc 0.46642408675799085
95 train_acc 0.45847317351598177
96 train_acc 0.46322488584474886
97 train_acc 0.45873287671232876
98 train_acc 0.43882134703196346
99 train_acc 0.46443778538812786
100 train_acc 0.458199200913242 val_acc 0.5608058608058608 test_acc 0.72283081203269
101 train_acc 0.4642579908675799 val_acc 0.5622710622710623 test_acc 0.7249174056685793
102 train_acc 0.4673972602739726 val_acc 0.5582417582417583 test_acc 0.7249174056685793
103 train_acc 0.4551027397260273 val_acc 0.5010989010989011 test_acc 0.7249174056685793
104 train_acc 0.44787385844748856 val_acc 0.5597069597069597 test_acc 0.7249174056685793
105 train_acc 0.44814783105022826 val_acc 0.5406593406593407 test_acc 0.7249174056685793
106 train_acc 0.47151255707762557 val_acc 0.6007326007326008 test_acc 0.7249174056685793
107 train_acc 0.4695690639269406 val_acc 0.5523809523809524 test_acc 0.7249174056685793
108 train_acc 0.4656535388127854 val_acc 0.5051282051282051 test_acc 0.7249174056685793
109 train_acc 0.44550513698630134 val_acc 0.5241758241758242 test_acc 0.7249174056685793
110 train_acc 0.4654280821917808 val_acc 0.575091575091575 test_acc 0.7249174056685793
111 train_acc 0.4607648401826484 val_acc 0.5875457875457875 test_acc 0.7249174056685793
112 train_acc 0.4740867579908675 val_acc 0.5600732600732601 test_acc 0.7249174056685793
113 train_acc 0.46042237442922374 val_acc 0.5776556776556777 test_acc 0.7249174056685793
114 train_acc 0.4687043378995434 val_acc 0.53992673992674 test_acc 0.7249174056685793
115 train_acc 0.46494292237442925 val_acc 0.4893772893772894 test_acc 0.7249174056685793
116 train_acc 0.475656392694064 val_acc 0.5336996336996338 test_acc 0.7249174056685793
117 train_acc 0.4692094748858447 val_acc 0.5087912087912088 test_acc 0.7249174056685793
118 train_acc 0.48459760273972596 val_acc 0.5816849816849817 test_acc 0.7249174056685793
119 train_acc 0.46515839041095886 val_acc 0.5835164835164836 test_acc 0.7249174056685793
120 train_acc 0.46081621004566203 val_acc 0.5241758241758242 test_acc 0.7249174056685793
121 train_acc 0.4771090182648402 val_acc 0.5223443223443224 test_acc 0.7249174056685793
122 train_acc 0.4643635844748858 val_acc 0.563003663003663 test_acc 0.7249174056685793
123 train_acc 0.4721332762557078 val_acc 0.552014652014652 test_acc 0.7249174056685793
124 train_acc 0.4708932648401827 val_acc 0.5523809523809524 test_acc 0.7249174056685793
125 train_acc 0.47816210045662105 val_acc 0.44871794871794873 test_acc 0.7249174056685793
126 train_acc 0.48010273972602746 val_acc 0.4644688644688645 test_acc 0.7249174056685793
127 train_acc 0.47875856164383557 val_acc 0.4714285714285715 test_acc 0.7249174056685793
128 train_acc 0.481361301369863 val_acc 0.47655677655677653 test_acc 0.7249174056685793
129 train_acc 0.4783761415525114 val_acc 0.512087912087912 test_acc 0.7249174056685793
130 train_acc 0.48766267123287677 val_acc 0.38021978021978026 test_acc 0.7249174056685793
131 train_acc 0.47396689497716893 val_acc 0.5644688644688646 test_acc 0.7249174056685793
132 train_acc 0.48426227168949765 val_acc 0.53003663003663 test_acc 0.7249174056685793
133 train_acc 0.4743264840182648 val_acc 0.5241758241758242 test_acc 0.7249174056685793
134 train_acc 0.4881906392694064 val_acc 0.5157509157509158 test_acc 0.7249174056685793
135 train_acc 0.48482020547945204 val_acc 0.5098901098901099 test_acc 0.7249174056685793
136 train_acc 0.4680964611872146 val_acc 0.5285714285714286 test_acc 0.7249174056685793
137 train_acc 0.4888042237442923 val_acc 0.4641025641025641 test_acc 0.7249174056685793
138 train_acc 0.4743493150684931 val_acc 0.5728937728937729 test_acc 0.7259607024865241
139 train_acc 0.49028538812785394 val_acc 0.35824175824175825 test_acc 0.7259607024865241
140 train_acc 0.48392123287671235 val_acc 0.5351648351648353 test_acc 0.7259607024865241
141 train_acc 0.4827368721461187 val_acc 0.5490842490842491 test_acc 0.7259607024865241
142 train_acc 0.48006563926940643 val_acc 0.46153846153846156 test_acc 0.7259607024865241
143 train_acc 0.4866267123287671 val_acc 0.4798534798534798 test_acc 0.7259607024865241
144 train_acc 0.4848244863013699 val_acc 0.4695970695970696 test_acc 0.7259607024865241
145 train_acc 0.4811144406392694 val_acc 0.48461538461538467 test_acc 0.7259607024865241
146 train_acc 0.49458618721461184 val_acc 0.5377289377289377 test_acc 0.7259607024865241
147 train_acc 0.4900171232876712 val_acc 0.49157509157509155 test_acc 0.7259607024865241
148 train_acc 0.4908961187214611 val_acc 0.5230769230769231 test_acc 0.7259607024865241
149 train_acc 0.49442208904109597 val_acc 0.36190476190476195 test_acc 0.7259607024865241
150 train_acc 0.46727739726027395 val_acc 0.5765567765567765 test_acc 0.7259607024865241
151 train_acc 0.4821461187214612 val_acc 0.5758241758241759 test_acc 0.7259607024865241
152 train_acc 0.474777397260274 val_acc 0.536996336996337 test_acc 0.7259607024865241
153 train_acc 0.48592608447488583 val_acc 0.4871794871794872 test_acc 0.7259607024865241
154 train_acc 0.4871475456621004 val_acc 0.45567765567765567 test_acc 0.7259607024865241
155 train_acc 0.48069634703196346 val_acc 0.5194139194139195 test_acc 0.7259607024865241
156 train_acc 0.48177796803652967 val_acc 0.5706959706959707 test_acc 0.7259607024865241
157 train_acc 0.48277682648401826 val_acc 0.5633699633699635 test_acc 0.7259607024865241
158 train_acc 0.4830921803652968 val_acc 0.5073260073260073 test_acc 0.7259607024865241
159 train_acc 0.4921860730593607 val_acc 0.552014652014652 test_acc 0.7259607024865241
160 train_acc 0.4881663812785388 val_acc 0.5322344322344322 test_acc 0.7259607024865241
161 train_acc 0.49899543378995426 val_acc 0.49304029304029307 test_acc 0.7259607024865241
162 train_acc 0.4760302511415525 val_acc 0.42490842490842495 test_acc 0.7259607024865241
163 train_acc 0.487017694063927 val_acc 0.4827838827838828 test_acc 0.7259607024865241
164 train_acc 0.48153253424657533 val_acc 0.4783882783882784 test_acc 0.7259607024865241
165 train_acc 0.4909417808219178 val_acc 0.5194139194139193 test_acc 0.7259607024865241
166 train_acc 0.48868721461187214 val_acc 0.5992673992673994 test_acc 0.7271778821074595
167 train_acc 0.4870833333333333 val_acc 0.5054945054945055 test_acc 0.7271778821074595
168 train_acc 0.4871675228310502 val_acc 0.48644688644688644 test_acc 0.7271778821074595
169 train_acc 0.48181506849315064 val_acc 0.5164835164835164 test_acc 0.7271778821074595
170 train_acc 0.500439497716895 val_acc 0.5487179487179488 test_acc 0.7271778821074595
171 train_acc 0.4969606164383561 val_acc 0.4897435897435898 test_acc 0.7271778821074595
172 train_acc 0.4835587899543379 val_acc 0.571062271062271 test_acc 0.7271778821074595
173 train_acc 0.48546375570776257 val_acc 0.47326007326007336 test_acc 0.7271778821074595
174 train_acc 0.47642123287671234 val_acc 0.5175824175824176 test_acc 0.7271778821074595
175 train_acc 0.47773116438356167 val_acc 0.4157509157509158 test_acc 0.7271778821074595
176 train_acc 0.4964126712328767 val_acc 0.5695970695970697 test_acc 0.7271778821074595
177 train_acc 0.48704908675799086 val_acc 0.48681318681318686 test_acc 0.7271778821074595
178 train_acc 0.4714269406392694 val_acc 0.43956043956043955 test_acc 0.7271778821074595
179 train_acc 0.49819634703196347 val_acc 0.49523809523809526 test_acc 0.7271778821074595
180 train_acc 0.4955565068493151 val_acc 0.5619047619047619 test_acc 0.7271778821074595
181 train_acc 0.4880565068493151 val_acc 0.5728937728937729 test_acc 0.7271778821074595
182 train_acc 0.48593607305936065 val_acc 0.4351648351648353 test_acc 0.7271778821074595
183 train_acc 0.496615296803653 val_acc 0.5117216117216118 test_acc 0.7271778821074595
184 train_acc 0.4909046803652969 val_acc 0.5413919413919415 test_acc 0.7271778821074595
185 train_acc 0.48573630136986307 val_acc 0.5908424908424909 test_acc 0.7271778821074595
186 train_acc 0.47991438356164384 val_acc 0.48791208791208796 test_acc 0.7271778821074595
187 train_acc 0.5002910958904109 val_acc 0.4743589743589744 test_acc 0.7271778821074595
188 train_acc 0.4682791095890411 val_acc 0.44322344322344326 test_acc 0.7271778821074595
189 train_acc 0.4944377853881279 val_acc 0.4996336996336996 test_acc 0.7271778821074595
190 train_acc 0.49790239726027397 val_acc 0.5146520146520147 test_acc 0.7271778821074595
191 train_acc 0.4923658675799087 val_acc 0.3981684981684982 test_acc 0.7271778821074595
192 train_acc 0.4931563926940639 val_acc 0.4534798534798535 test_acc 0.7271778821074595
193 train_acc 0.5055336757990868 val_acc 0.532967032967033 test_acc 0.7271778821074595
194 train_acc 0.500958904109589 val_acc 0.5150183150183151 test_acc 0.7271778821074595
195 train_acc 0.49692636986301364 val_acc 0.5794871794871794 test_acc 0.7271778821074595
196 train_acc 0.48958333333333337 val_acc 0.4443223443223444 test_acc 0.7271778821074595
197 train_acc 0.5078681506849315 val_acc 0.5029304029304029 test_acc 0.7271778821074595
198 train_acc 0.5189069634703196 val_acc 0.5322344322344322 test_acc 0.7271778821074595
199 train_acc 0.4887071917808219 val_acc 0.4285714285714286 test_acc 0.7271778821074595
Finished training!
Best validation score: 0.5992673992673994
Test score: 0.7271778821074595
GCN_graph_UGTs(
  (convs): ModuleList(
    (0): Graphlevel_GCNConv(64, 64)
    (1): Graphlevel_GCNConv(64, 64)
    (2): Graphlevel_GCNConv(64, 64)
  )
  (atom_encoder): SLT_AtomEncoder(
    (atom_embedding_list): ModuleList(
      (0): Embedding(119, 64)
      (1): Embedding(5, 64)
      (2): Embedding(12, 64)
      (3): Embedding(12, 64)
      (4): Embedding(10, 64)
      (5): Embedding(6, 64)
      (6): Embedding(6, 64)
      (7): Embedding(2, 64)
      (8): Embedding(2, 64)
    )
    (weight_scores_list): ParameterList(
        (0): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (1): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (2): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (3): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (4): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (5): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (6): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (7): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (8): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
    )
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (graph_pred_linear): Linear(in_features=64, out_features=1, bias=True)
)
Name: convs.0.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.0.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.0.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.0.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.0.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.0.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.1.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.1.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.1.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.1.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.1.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.2.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.2.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.2.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.2.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.2.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.atom_embedding_list.0.weight, Shape: torch.Size([119, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.1.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.2.weight, Shape: torch.Size([12, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.3.weight, Shape: torch.Size([12, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.4.weight, Shape: torch.Size([10, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.5.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.6.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.7.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.8.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: atom_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.3, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.4, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.5, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.6, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.7, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.8, Shape: torch.Size([1, 64]), Requires Grad: True
Name: batch_norms.0.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.0.bias, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.1.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.1.bias, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.2.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.2.bias, Shape: torch.Size([64]), Requires Grad: True
Name: graph_pred_linear.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: graph_pred_linear.bias, Shape: torch.Size([1]), Requires Grad: True
/artic/h-ito/BingoGCN/__outputs__/Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molbace_Msup_L3_M16_S1875/dump..Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molbace_Msup_L3_M16_S1875.pth
0 train_acc 0.20454052511415524
1 train_acc 0.579517694063927
2 train_acc 0.5218578767123287
3 train_acc 0.4908276255707763
4 train_acc 0.4632191780821918
5 train_acc 0.4494506278538813
6 train_acc 0.43943207762557074
7 train_acc 0.4347288812785388
8 train_acc 0.43388698630136985
9 train_acc 0.4628681506849315
10 train_acc 0.4353909817351598
11 train_acc 0.43045376712328765
12 train_acc 0.42270262557077626
13 train_acc 0.40606735159817353
14 train_acc 0.43045947488584474
15 train_acc 0.4550485159817351
16 train_acc 0.43275970319634705
17 train_acc 0.42108875570776255
18 train_acc 0.4321218607305936
19 train_acc 0.4268778538812786
20 train_acc 0.443087899543379
21 train_acc 0.4350770547945205
22 train_acc 0.4364583333333334
23 train_acc 0.4519920091324201
24 train_acc 0.42599885844748864
25 train_acc 0.44913812785388124
26 train_acc 0.4358704337899543
27 train_acc 0.43149257990867573
28 train_acc 0.4350513698630137
29 train_acc 0.43918664383561645
30 train_acc 0.4473630136986302
31 train_acc 0.43240154109589035
32 train_acc 0.4509617579908676
33 train_acc 0.42805650684931507
34 train_acc 0.4361087328767123
35 train_acc 0.4329651826484019
36 train_acc 0.4355679223744292
37 train_acc 0.43702910958904106
38 train_acc 0.4461130136986301
39 train_acc 0.45795662100456624
40 train_acc 0.4192608447488584
41 train_acc 0.43267408675799085
42 train_acc 0.4321946347031963
43 train_acc 0.4107648401826484
44 train_acc 0.42527111872146117
45 train_acc 0.42474885844748855
46 train_acc 0.4439954337899543
47 train_acc 0.4137442922374429
48 train_acc 0.448035102739726
49 train_acc 0.4365867579908676
50 train_acc 0.4387157534246575
51 train_acc 0.4408504566210045
52 train_acc 0.4180222602739726
53 train_acc 0.4312442922374429
54 train_acc 0.4391495433789955
55 train_acc 0.4389925799086758
56 train_acc 0.4509332191780822
57 train_acc 0.4466609589041096
58 train_acc 0.45046518264840185
59 train_acc 0.45515696347031964
60 train_acc 0.4451227168949771
61 train_acc 0.43993436073059355
62 train_acc 0.45953196347031966
63 train_acc 0.4401769406392694
64 train_acc 0.4418635844748858
65 train_acc 0.4484874429223744
66 train_acc 0.4574158105022831
67 train_acc 0.4307377283105023
68 train_acc 0.4294777397260274
69 train_acc 0.4304366438356164
70 train_acc 0.4495262557077625
71 train_acc 0.45098744292237447
72 train_acc 0.4510074200913242
73 train_acc 0.44141267123287675
74 train_acc 0.4325428082191781
75 train_acc 0.4328767123287671
76 train_acc 0.4278909817351598
77 train_acc 0.40611015981735155
78 train_acc 0.4491495433789954
79 train_acc 0.417865296803653
80 train_acc 0.44472602739726025
81 train_acc 0.41948202054794514
82 train_acc 0.4595077054794521
83 train_acc 0.4411929223744292
84 train_acc 0.4506706621004567
85 train_acc 0.4393493150684931
86 train_acc 0.4473401826484018
87 train_acc 0.4639041095890411
88 train_acc 0.4532477168949772
89 train_acc 0.41585616438356166
90 train_acc 0.41829623287671236
91 train_acc 0.43445205479452054
92 train_acc 0.4511900684931507
93 train_acc 0.42490011415525114
94 train_acc 0.4508861301369863
95 train_acc 0.4348030821917808
96 train_acc 0.42851883561643833
97 train_acc 0.41839326484018263
98 train_acc 0.4426055936073059
99 train_acc 0.43902682648401825
100 train_acc 0.4268864155251142 val_acc 0.4186813186813187 test_acc 0.4047991653625456
101 train_acc 0.44525684931506854 val_acc 0.5527472527472528 test_acc 0.7543035993740218
102 train_acc 0.4438527397260274 val_acc 0.5527472527472528 test_acc 0.7543035993740218
103 train_acc 0.4597360159817352 val_acc 0.5908424908424909 test_acc 0.7543035993740218
104 train_acc 0.439009703196347 val_acc 0.5644688644688645 test_acc 0.7543035993740218
105 train_acc 0.4411358447488584 val_acc 0.5615384615384615 test_acc 0.7543035993740218
106 train_acc 0.4491866438356164 val_acc 0.5721611721611722 test_acc 0.7543035993740218
107 train_acc 0.46086187214611873 val_acc 0.580952380952381 test_acc 0.7543035993740218
108 train_acc 0.4258190639269406 val_acc 0.5761904761904761 test_acc 0.7543035993740218
109 train_acc 0.44566210045662097 val_acc 0.5838827838827839 test_acc 0.7556946617979481
110 train_acc 0.4538356164383561 val_acc 0.5611721611721612 test_acc 0.7556946617979481
111 train_acc 0.4482020547945205 val_acc 0.5637362637362637 test_acc 0.7556946617979481
112 train_acc 0.46774828767123283 val_acc 0.5897435897435898 test_acc 0.773604590505999
113 train_acc 0.464337899543379 val_acc 0.567032967032967 test_acc 0.773604590505999
114 train_acc 0.4546090182648402 val_acc 0.6098901098901099 test_acc 0.773604590505999
115 train_acc 0.4820690639269406 val_acc 0.5908424908424909 test_acc 0.773604590505999
116 train_acc 0.4439811643835616 val_acc 0.37655677655677655 test_acc 0.773604590505999
117 train_acc 0.45176084474885847 val_acc 0.5172161172161173 test_acc 0.773604590505999
118 train_acc 0.4770148401826484 val_acc 0.48241758241758237 test_acc 0.773604590505999
119 train_acc 0.45582477168949764 val_acc 0.5135531135531136 test_acc 0.773604590505999
120 train_acc 0.4433247716894977 val_acc 0.5699633699633699 test_acc 0.773604590505999
121 train_acc 0.44504851598173517 val_acc 0.5721611721611722 test_acc 0.773604590505999
122 train_acc 0.4384046803652968 val_acc 0.621978021978022 test_acc 0.773604590505999
123 train_acc 0.444041095890411 val_acc 0.6249084249084249 test_acc 0.773604590505999
124 train_acc 0.45850171232876713 val_acc 0.5864468864468865 test_acc 0.773604590505999
125 train_acc 0.4350713470319635 val_acc 0.5648351648351648 test_acc 0.773604590505999
126 train_acc 0.4445776255707762 val_acc 0.4743589743589744 test_acc 0.773604590505999
127 train_acc 0.4486957762557078 val_acc 0.5179487179487179 test_acc 0.773604590505999
128 train_acc 0.4454309360730594 val_acc 0.5798534798534799 test_acc 0.773604590505999
129 train_acc 0.4481107305936073 val_acc 0.6197802197802198 test_acc 0.773604590505999
130 train_acc 0.4514954337899543 val_acc 0.5296703296703297 test_acc 0.773604590505999
131 train_acc 0.45729166666666665 val_acc 0.5923076923076923 test_acc 0.773604590505999
132 train_acc 0.4604794520547945 val_acc 0.5230769230769231 test_acc 0.773604590505999
133 train_acc 0.46400970319634705 val_acc 0.45787545787545786 test_acc 0.773604590505999
134 train_acc 0.4799058219178083 val_acc 0.5003663003663004 test_acc 0.773604590505999
135 train_acc 0.4389183789954338 val_acc 0.5754578754578754 test_acc 0.773604590505999
136 train_acc 0.44347888127853885 val_acc 0.6018315018315019 test_acc 0.773604590505999
137 train_acc 0.45301369863013696 val_acc 0.5593406593406594 test_acc 0.773604590505999
138 train_acc 0.46502283105022835 val_acc 0.5560439560439561 test_acc 0.773604590505999
139 train_acc 0.46472031963470317 val_acc 0.6347985347985349 test_acc 0.773604590505999
140 train_acc 0.4585930365296804 val_acc 0.5336996336996337 test_acc 0.773604590505999
141 train_acc 0.46238584474885847 val_acc 0.5560439560439561 test_acc 0.773604590505999
142 train_acc 0.47692922374429225 val_acc 0.4780219780219781 test_acc 0.773604590505999
143 train_acc 0.4839069634703197 val_acc 0.532967032967033 test_acc 0.773604590505999
144 train_acc 0.4667094748858448 val_acc 0.5703296703296703 test_acc 0.773604590505999
145 train_acc 0.4565382420091324 val_acc 0.5135531135531135 test_acc 0.773604590505999
146 train_acc 0.48291666666666666 val_acc 0.5666666666666667 test_acc 0.773604590505999
147 train_acc 0.4760416666666667 val_acc 0.5263736263736264 test_acc 0.773604590505999
148 train_acc 0.4680764840182649 val_acc 0.5336996336996337 test_acc 0.773604590505999
149 train_acc 0.45759988584474887 val_acc 0.5322344322344322 test_acc 0.773604590505999
150 train_acc 0.479962899543379 val_acc 0.5553113553113553 test_acc 0.773604590505999
151 train_acc 0.4810131278538813 val_acc 0.5901098901098901 test_acc 0.773604590505999
152 train_acc 0.45701484018264843 val_acc 0.5384615384615385 test_acc 0.773604590505999
153 train_acc 0.45962899543379 val_acc 0.5945054945054945 test_acc 0.773604590505999
154 train_acc 0.47991152968036527 val_acc 0.5974358974358973 test_acc 0.773604590505999
155 train_acc 0.4602054794520548 val_acc 0.5131868131868131 test_acc 0.773604590505999
156 train_acc 0.47324771689497713 val_acc 0.46923076923076923 test_acc 0.773604590505999
157 train_acc 0.46386700913242007 val_acc 0.5901098901098901 test_acc 0.773604590505999
158 train_acc 0.46312214611872143 val_acc 0.49853479853479854 test_acc 0.773604590505999
159 train_acc 0.4746033105022831 val_acc 0.5516483516483517 test_acc 0.773604590505999
160 train_acc 0.45053082191780824 val_acc 0.5461538461538461 test_acc 0.773604590505999
161 train_acc 0.48076484018264837 val_acc 0.528937728937729 test_acc 0.773604590505999
162 train_acc 0.4552939497716895 val_acc 0.5135531135531135 test_acc 0.773604590505999
163 train_acc 0.467240296803653 val_acc 0.6274725274725275 test_acc 0.773604590505999
164 train_acc 0.47984731735159813 val_acc 0.5626373626373627 test_acc 0.773604590505999
165 train_acc 0.46627568493150684 val_acc 0.5736263736263737 test_acc 0.773604590505999
166 train_acc 0.4603224885844749 val_acc 0.49230769230769234 test_acc 0.773604590505999
167 train_acc 0.4645590753424657 val_acc 0.44945054945054946 test_acc 0.773604590505999
168 train_acc 0.46300228310502284 val_acc 0.6183150183150183 test_acc 0.773604590505999
169 train_acc 0.4693236301369863 val_acc 0.6117216117216118 test_acc 0.773604590505999
170 train_acc 0.46458333333333335 val_acc 0.5443223443223444 test_acc 0.773604590505999
171 train_acc 0.47500000000000003 val_acc 0.5996336996336996 test_acc 0.773604590505999
172 train_acc 0.46461187214611865 val_acc 0.5271062271062271 test_acc 0.773604590505999
173 train_acc 0.458898401826484 val_acc 0.49413919413919416 test_acc 0.773604590505999
174 train_acc 0.4658818493150685 val_acc 0.45860805860805864 test_acc 0.773604590505999
175 train_acc 0.44109303652968035 val_acc 0.6153846153846154 test_acc 0.773604590505999
176 train_acc 0.4643150684931507 val_acc 0.6168498168498169 test_acc 0.773604590505999
177 train_acc 0.4694292237442922 val_acc 0.4054945054945055 test_acc 0.773604590505999
178 train_acc 0.4937471461187215 val_acc 0.5597069597069597 test_acc 0.773604590505999
179 train_acc 0.4836700913242009 val_acc 0.5476190476190477 test_acc 0.773604590505999
180 train_acc 0.47878139269406395 val_acc 0.43846153846153846 test_acc 0.773604590505999
181 train_acc 0.46635559360730594 val_acc 0.5695970695970697 test_acc 0.773604590505999
182 train_acc 0.4791595319634703 val_acc 0.5798534798534799 test_acc 0.773604590505999
183 train_acc 0.4725085616438356 val_acc 0.5996336996336996 test_acc 0.773604590505999
184 train_acc 0.459486301369863 val_acc 0.4652014652014653 test_acc 0.773604590505999
185 train_acc 0.4831050228310503 val_acc 0.5659340659340659 test_acc 0.773604590505999
186 train_acc 0.47049086757990866 val_acc 0.5197802197802197 test_acc 0.773604590505999
187 train_acc 0.4853852739726027 val_acc 0.5494505494505495 test_acc 0.773604590505999
188 train_acc 0.4946575342465754 val_acc 0.6076923076923078 test_acc 0.773604590505999
189 train_acc 0.46726312785388124 val_acc 0.5285714285714287 test_acc 0.773604590505999
190 train_acc 0.42559931506849313 val_acc 0.5853479853479854 test_acc 0.773604590505999
191 train_acc 0.4697973744292238 val_acc 0.5619047619047619 test_acc 0.773604590505999
192 train_acc 0.46970890410958904 val_acc 0.5600732600732601 test_acc 0.773604590505999
193 train_acc 0.4807477168949772 val_acc 0.5512820512820513 test_acc 0.773604590505999
194 train_acc 0.4555679223744292 val_acc 0.43553113553113554 test_acc 0.773604590505999
195 train_acc 0.4860916095890411 val_acc 0.45531135531135536 test_acc 0.773604590505999
196 train_acc 0.4784674657534247 val_acc 0.5868131868131867 test_acc 0.773604590505999
197 train_acc 0.48060787671232874 val_acc 0.4681318681318682 test_acc 0.773604590505999
198 train_acc 0.4889640410958904 val_acc 0.5516483516483517 test_acc 0.773604590505999
199 train_acc 0.5023601598173516 val_acc 0.5472527472527473 test_acc 0.773604590505999
Finished training!
Best validation score: 0.5897435897435898
Test score: 0.773604590505999
acc mean: 0.7487393496783167  acc std: 0.01909705040890062 ece mean: 0.0 ece std 0.0
End time: 2025-03-28 22:46:02
Duration: 0:13:27.679118
