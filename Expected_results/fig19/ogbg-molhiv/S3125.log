Start time: 2025-03-28 22:59:46
Namespace(num_layers=3, epochs=200, dim_hidden=64, repeat_times=3, linear_sparsity=0.3125, train_mode='score_only', rerand_freq=0, exp_name='Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molhiv_Msup_L3_M16_S3125', weight_l1=0.0, sampling=None, samplingtype=None, sparse_decay=True, attack=None, auroc=False, attack_eps=0, dataset='ogbg-molhiv', random_seed=None, resume=False, cuda=True, type_model='GCN_graph_UGTs', dropout=0.0, lr=0.01, weight_decay=0.0005, transductive=True, activation='relu', type_norm='batch', command='train', force_restart=False, seed_by_time=True, print_train_loss=False, num_gpus=1, output_dir='__outputs__', sync_dir='__sync__', save_best_model=True, optimizer='Adam', scheduler='CustomCosineLR', warm_epochs=0, finetuning_epochs=0, finetuning_lr=None, lr_milestones=[900, 1000, 1100], checkpoint_epochs=[], multisteplr_gamma=0.1, learning_framework='GraphLevelLearning', bn_track_running_stats=True, bn_affine=True, bn_momentum=0.1, init_mode='xor16_offset', init_mode_mask='kaiming_uniform', init_mode_linear=None, init_scale=1.0, init_scale_score=1.0, heads=1, sparsity_list=[0.3125, 0.541667, 0.770833], num_mask=3, enable_mask=True, enable_abs_comp=True, validate=False, pretrained_path=None, prunedw_path=None, enable_sw_mm=False, BN_GIN=False, evatime=False, drawadj=False, evanum=50, METIS=False, spadj=False, adjsparsity_ratio=0.0, enable_feat_pruning=False, featsparsity_ratio=0.0, enable_node_pruning=False, x_pruning_layer=0, regular_weight_pruning=None, num_of_weight_blocks=1, global_th_for_rowbyrow=False, download_prunedw=False, gra_part=False, no_edge_weight=False, sparse_tensor=False, original_edge_weight=False, only_train_data=False, flowgnn_debug=False, nmsparsity=True, M=16, unstructured_for_last_layer=False, xor_seed_using_instance_number=False, outgoing_centroids=False, folded_layer=0, BN_track_running_stats=True, folded_SM=False, half_folded=False, batch_size=256, elastic_net=False, elastic_lambda=5e-08, l1_ratio=0.5, no_norm=False, adp=False, SLT_Bonder=False, SLTAtom=True, SLTBond=True, SLTRoot=False, SLTAtom_ini='xor16_atom', SLTBond_ini='xor16_bond', SLTRoot_ini='default', dense_for_last_layer=True, local_pruning=False, local_sparsity_list=None, inference_time=False, sparsity_profiling=False, nm_decay=0.0001, num_feats=9, num_classes=2)
GCN_graph_UGTs(
  (convs): ModuleList(
    (0): Graphlevel_GCNConv(64, 64)
    (1): Graphlevel_GCNConv(64, 64)
    (2): Graphlevel_GCNConv(64, 64)
  )
  (atom_encoder): SLT_AtomEncoder(
    (atom_embedding_list): ModuleList(
      (0): Embedding(119, 64)
      (1): Embedding(5, 64)
      (2): Embedding(12, 64)
      (3): Embedding(12, 64)
      (4): Embedding(10, 64)
      (5): Embedding(6, 64)
      (6): Embedding(6, 64)
      (7): Embedding(2, 64)
      (8): Embedding(2, 64)
    )
    (weight_scores_list): ParameterList(
        (0): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (1): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (2): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (3): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (4): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (5): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (6): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (7): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (8): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
    )
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (graph_pred_linear): Linear(in_features=64, out_features=1, bias=True)
)
Name: convs.0.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.0.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.0.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.0.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.0.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.0.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.1.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.1.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.1.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.1.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.1.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.2.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.2.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.2.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.2.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.2.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.atom_embedding_list.0.weight, Shape: torch.Size([119, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.1.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.2.weight, Shape: torch.Size([12, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.3.weight, Shape: torch.Size([12, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.4.weight, Shape: torch.Size([10, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.5.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.6.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.7.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.8.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: atom_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.3, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.4, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.5, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.6, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.7, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.8, Shape: torch.Size([1, 64]), Requires Grad: True
Name: batch_norms.0.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.0.bias, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.1.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.1.bias, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.2.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.2.bias, Shape: torch.Size([64]), Requires Grad: True
Name: graph_pred_linear.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: graph_pred_linear.bias, Shape: torch.Size([1]), Requires Grad: True
/artic/h-ito/BingoGCN/__outputs__/Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molhiv_Msup_L3_M16_S3125/dump..Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molhiv_Msup_L3_M16_S3125.pth
0 train_acc 0.4884767120372128
1 train_acc 0.6300097257016879
2 train_acc 0.6694534614947716
3 train_acc 0.682234662579203
4 train_acc 0.6697091757353765
5 train_acc 0.6793131459623141
6 train_acc 0.6867891031337541
7 train_acc 0.6852793972187148
8 train_acc 0.6891556324489556
9 train_acc 0.698453678532778
10 train_acc 0.689110036013751
11 train_acc 0.697274002127526
12 train_acc 0.695209091052621
13 train_acc 0.6966796722018707
14 train_acc 0.6964896357944371
15 train_acc 0.7022005060050941
16 train_acc 0.7058768243187549
17 train_acc 0.7179009041575748
18 train_acc 0.7037833610073024
19 train_acc 0.7085490727340801
20 train_acc 0.7054228078751272
21 train_acc 0.713475640687583
22 train_acc 0.7196649274578402
23 train_acc 0.7098675119837377
24 train_acc 0.7141135294337164
25 train_acc 0.7115580273715989
26 train_acc 0.7081284782980448
27 train_acc 0.7117281233481224
28 train_acc 0.7039702833243046
29 train_acc 0.7005340959839049
30 train_acc 0.709450518615238
31 train_acc 0.7080725015614024
32 train_acc 0.7163307618208309
33 train_acc 0.7205961173879327
34 train_acc 0.7183081964295455
35 train_acc 0.7232537308597494
36 train_acc 0.7285596667928363
37 train_acc 0.7215207074967409
38 train_acc 0.7196977727820193
39 train_acc 0.7222328730664959
40 train_acc 0.6975355857237587
41 train_acc 0.707885963700009
42 train_acc 0.6997172303366846
43 train_acc 0.7107813117051253
44 train_acc 0.7139640146474511
45 train_acc 0.7198093674300691
46 train_acc 0.7264251692527371
47 train_acc 0.7266022495061539
48 train_acc 0.7259437795697625
49 train_acc 0.7258360038474266
50 train_acc 0.724012774383405
51 train_acc 0.723102332241001
52 train_acc 0.7204229970272866
53 train_acc 0.7279225341427338
54 train_acc 0.7320653508921215
55 train_acc 0.7224054680044766
56 train_acc 0.7292036427527758
57 train_acc 0.7295951851599726
58 train_acc 0.7325316314696702
59 train_acc 0.7300657972707139
60 train_acc 0.7057294752990859
61 train_acc 0.7114885306127136
62 train_acc 0.7180197265710702
63 train_acc 0.7258849578616149
64 train_acc 0.7263453306379748
65 train_acc 0.7291503956509562
66 train_acc 0.7200600196718245
67 train_acc 0.7276202495127153
68 train_acc 0.7261201037271485
69 train_acc 0.7200734756181327
70 train_acc 0.7038362236535134
71 train_acc 0.7173490565766926
72 train_acc 0.7192204839588717
73 train_acc 0.7212063125150452
74 train_acc 0.7190757107917817
75 train_acc 0.7273974959329722
76 train_acc 0.726916260032241
77 train_acc 0.7240182849137979
78 train_acc 0.7329231995072406
79 train_acc 0.7337022603529282
80 train_acc 0.7281689061120447
81 train_acc 0.7210726244846758
82 train_acc 0.720602153340991
83 train_acc 0.7232529106877839
84 train_acc 0.7315188856897626
85 train_acc 0.7361185766694703
86 train_acc 0.7315204747729456
87 train_acc 0.7265619713735378
88 train_acc 0.7347714442162088
89 train_acc 0.731198595722065
90 train_acc 0.7329556219302502
91 train_acc 0.7348313552152479
92 train_acc 0.739311967477721
93 train_acc 0.7410027776148824
94 train_acc 0.7407644663981696
95 train_acc 0.7400475976548003
96 train_acc 0.7497447855516866
97 train_acc 0.7413918979517435
98 train_acc 0.7366774085272458
99 train_acc 0.7455751722463648
100 train_acc 0.7414399420876575 val_acc 0.7277489956888105 test_acc 0.726319550396879
101 train_acc 0.7438076888456203 val_acc 0.6870345874975503 test_acc 0.726319550396879
102 train_acc 0.7421328976921591 val_acc 0.5519884136782285 test_acc 0.726319550396879
103 train_acc 0.7455067391479971 val_acc 0.6780264060356652 test_acc 0.726319550396879
104 train_acc 0.7405770955496238 val_acc 0.7117259455222418 test_acc 0.726319550396879
105 train_acc 0.7404354108425913 val_acc 0.46396574319028017 test_acc 0.726319550396879
106 train_acc 0.7462098700109451 val_acc 0.6740060993533216 test_acc 0.726319550396879
107 train_acc 0.7389841678104648 val_acc 0.6855556780325298 test_acc 0.726319550396879
108 train_acc 0.7366384759892607 val_acc 0.6770129090730942 test_acc 0.726319550396879
109 train_acc 0.742376975743004 val_acc 0.6561535493827162 test_acc 0.726319550396879
110 train_acc 0.7397984960506669 val_acc 0.6780264060356653 test_acc 0.726319550396879
111 train_acc 0.745173095755487 val_acc 0.7102960268469527 test_acc 0.726319550396879
112 train_acc 0.7464306884974573 val_acc 0.7279939496374682 test_acc 0.7302854439058305
113 train_acc 0.7411166149206504 val_acc 0.7030362041936116 test_acc 0.7302854439058305
114 train_acc 0.7440584051633107 val_acc 0.7396843768371545 test_acc 0.7302854439058305
115 train_acc 0.7456689409693531 val_acc 0.6978799235743681 test_acc 0.7302854439058305
116 train_acc 0.7484769406601481 val_acc 0.6526553008034489 test_acc 0.7302854439058305
117 train_acc 0.7486494330766332 val_acc 0.739981383499902 test_acc 0.7360764016300045
118 train_acc 0.7438185945697234 val_acc 0.5853848226533411 test_acc 0.7360764016300045
119 train_acc 0.7392642052759202 val_acc 0.6569389329805997 test_acc 0.7360764016300045
120 train_acc 0.7456658012485479 val_acc 0.7339004017244757 test_acc 0.7360764016300045
121 train_acc 0.7445871597772905 val_acc 0.7240410052910053 test_acc 0.7360764016300045
122 train_acc 0.7426157483064474 val_acc 0.6923317166372722 test_acc 0.7360764016300045
123 train_acc 0.7457210475195335 val_acc 0.636212766999804 test_acc 0.7360764016300045
124 train_acc 0.7450606681202848 val_acc 0.6884032676856751 test_acc 0.7360764016300045
125 train_acc 0.7474242883880463 val_acc 0.7275775279247501 test_acc 0.7360764016300045
126 train_acc 0.742927593065938 val_acc 0.7160983735057809 test_acc 0.7360764016300045
127 train_acc 0.7507836102370584 val_acc 0.7479393249069175 test_acc 0.7360764016300045
128 train_acc 0.7508468916302682 val_acc 0.7018328679208308 test_acc 0.7360764016300045
129 train_acc 0.7373181935056323 val_acc 0.611150916127768 test_acc 0.7360764016300045
130 train_acc 0.7445248010775419 val_acc 0.7011714922594552 test_acc 0.7360764016300045
131 train_acc 0.7450405482767571 val_acc 0.7080608220654516 test_acc 0.7360764016300045
132 train_acc 0.7496896930629445 val_acc 0.6808341906721536 test_acc 0.7360764016300045
133 train_acc 0.7538992513060213 val_acc 0.6755248138349991 test_acc 0.7360764016300045
134 train_acc 0.7569831491568837 val_acc 0.753704928473447 test_acc 0.7360764016300045
135 train_acc 0.75458538923106 val_acc 0.7565433323535176 test_acc 0.7360764016300045
136 train_acc 0.7517002036692033 val_acc 0.7039884626690183 test_acc 0.7360764016300045
137 train_acc 0.7433784185280128 val_acc 0.7285787771898883 test_acc 0.7360764016300045
138 train_acc 0.7522218971151682 val_acc 0.7216741377621008 test_acc 0.7360764016300045
139 train_acc 0.754105678337577 val_acc 0.7369286449147558 test_acc 0.7360764016300045
140 train_acc 0.7433995251409363 val_acc 0.7082965902410346 test_acc 0.7360764016300045
141 train_acc 0.7509449534408881 val_acc 0.7078434254360181 test_acc 0.7360764016300045
142 train_acc 0.7513097121073375 val_acc 0.6447279786400156 test_acc 0.7360764016300045
143 train_acc 0.7499259025889959 val_acc 0.7009265383107975 test_acc 0.7360764016300045
144 train_acc 0.751439811885358 val_acc 0.680644351361944 test_acc 0.7360764016300045
145 train_acc 0.7519951580122806 val_acc 0.6922367969821673 test_acc 0.7360764016300045
146 train_acc 0.7532288376153828 val_acc 0.6828764942190868 test_acc 0.7360764016300045
147 train_acc 0.7537584124013281 val_acc 0.6293632422104645 test_acc 0.7360764016300045
148 train_acc 0.7504299879680774 val_acc 0.6762902949245542 test_acc 0.7360764016300045
149 train_acc 0.7557763045552761 val_acc 0.6888258132471095 test_acc 0.7360764016300045
150 train_acc 0.7475355882867961 val_acc 0.6610327258475407 test_acc 0.7360764016300045
151 train_acc 0.7559053791183398 val_acc 0.716251469723692 test_acc 0.7360764016300045
152 train_acc 0.7498421809725845 val_acc 0.7320877425044091 test_acc 0.7360764016300045
153 train_acc 0.7432184978099358 val_acc 0.7447886047423083 test_acc 0.7360764016300045
154 train_acc 0.7438710599451387 val_acc 0.7141601753870273 test_acc 0.7360764016300045
155 train_acc 0.7421460332587934 val_acc 0.7009051048402901 test_acc 0.7360764016300045
156 train_acc 0.7518010079298326 val_acc 0.6420426709778562 test_acc 0.7360764016300045
157 train_acc 0.7535580213228308 val_acc 0.7089610278267685 test_acc 0.7360764016300045
158 train_acc 0.7504884636661768 val_acc 0.732225529100529 test_acc 0.7360764016300045
159 train_acc 0.7599559905975485 val_acc 0.7334502988438173 test_acc 0.7360764016300045
160 train_acc 0.7583202216883814 val_acc 0.6918188443072703 test_acc 0.7360764016300045
161 train_acc 0.749649876277059 val_acc 0.7653249314128944 test_acc 0.7415361439966011
162 train_acc 0.7549022447286523 val_acc 0.7181161816578483 test_acc 0.7415361439966011
163 train_acc 0.7549935401205571 val_acc 0.6824860988634137 test_acc 0.7415361439966011
164 train_acc 0.7501772084052862 val_acc 0.6437512247697433 test_acc 0.7415361439966011
165 train_acc 0.7518774377048636 val_acc 0.6792879188712522 test_acc 0.7415361439966011
166 train_acc 0.7525314095106321 val_acc 0.7043007789535567 test_acc 0.7415361439966011
167 train_acc 0.7520191736726439 val_acc 0.7298647854203411 test_acc 0.7415361439966011
168 train_acc 0.7518026226433896 val_acc 0.7285634675680973 test_acc 0.7415361439966011
169 train_acc 0.7529698683172902 val_acc 0.7561605918087398 test_acc 0.7415361439966011
170 train_acc 0.7507458054355256 val_acc 0.721971144424848 test_acc 0.7415361439966011
171 train_acc 0.7524125230212019 val_acc 0.7105562904174014 test_acc 0.7415361439966011
172 train_acc 0.7506595464120962 val_acc 0.6119776357044875 test_acc 0.7415361439966011
173 train_acc 0.7513090841631764 val_acc 0.7469105183225553 test_acc 0.7415361439966011
174 train_acc 0.7495275040567756 val_acc 0.5978897217323144 test_acc 0.7415361439966011
175 train_acc 0.7452920975815999 val_acc 0.7166648295120517 test_acc 0.7415361439966011
176 train_acc 0.7516570933802691 val_acc 0.7065084264158339 test_acc 0.7415361439966011
177 train_acc 0.7526740681718737 val_acc 0.7387933568489123 test_acc 0.7415361439966011
178 train_acc 0.7483836076535167 val_acc 0.6651755095042131 test_acc 0.7415361439966011
179 train_acc 0.7472029444788689 val_acc 0.6790307172251616 test_acc 0.7415361439966011
180 train_acc 0.7505700707767398 val_acc 0.7372164658044287 test_acc 0.7415361439966011
181 train_acc 0.7546611269859952 val_acc 0.7359978199098568 test_acc 0.7415361439966011
182 train_acc 0.7463415332417748 val_acc 0.7143836958651774 test_acc 0.7415361439966011
183 train_acc 0.7498242397108401 val_acc 0.7628080295904369 test_acc 0.7415361439966011
184 train_acc 0.7598515852693835 val_acc 0.7263098912404469 test_acc 0.7415361439966011
185 train_acc 0.7475496978076394 val_acc 0.684044618361748 test_acc 0.7415361439966011
186 train_acc 0.7514999151122016 val_acc 0.7344209288653731 test_acc 0.7415361439966011
187 train_acc 0.7527086691766662 val_acc 0.7168852880658436 test_acc 0.7415361439966011
188 train_acc 0.753567645528238 val_acc 0.7783258622378992 test_acc 0.7415361439966011
189 train_acc 0.761304148265767 val_acc 0.7620364246521654 test_acc 0.7415361439966011
190 train_acc 0.7565857758396203 val_acc 0.7629917450519301 test_acc 0.7415361439966011
191 train_acc 0.757335771841282 val_acc 0.7295677787575936 test_acc 0.7415361439966011
192 train_acc 0.7589750392964892 val_acc 0.7171884185773074 test_acc 0.7415361439966011
193 train_acc 0.7577961958783899 val_acc 0.7644553448951598 test_acc 0.7415361439966011
194 train_acc 0.7569513546780353 val_acc 0.7645380168528317 test_acc 0.7415361439966011
195 train_acc 0.7624954864911526 val_acc 0.777143959435626 test_acc 0.7415361439966011
196 train_acc 0.7566085868724096 val_acc 0.5897174456202233 test_acc 0.7415361439966011
197 train_acc 0.7624016408770427 val_acc 0.7560473006074857 test_acc 0.7415361439966011
198 train_acc 0.7435418121617561 val_acc 0.7473728689006467 test_acc 0.7415361439966011
199 train_acc 0.764141520365075 val_acc 0.7241665441896923 test_acc 0.7415361439966011
Finished training!
Best validation score: 0.7653249314128944
Test score: 0.7415361439966011
GCN_graph_UGTs(
  (convs): ModuleList(
    (0): Graphlevel_GCNConv(64, 64)
    (1): Graphlevel_GCNConv(64, 64)
    (2): Graphlevel_GCNConv(64, 64)
  )
  (atom_encoder): SLT_AtomEncoder(
    (atom_embedding_list): ModuleList(
      (0): Embedding(119, 64)
      (1): Embedding(5, 64)
      (2): Embedding(12, 64)
      (3): Embedding(12, 64)
      (4): Embedding(10, 64)
      (5): Embedding(6, 64)
      (6): Embedding(6, 64)
      (7): Embedding(2, 64)
      (8): Embedding(2, 64)
    )
    (weight_scores_list): ParameterList(
        (0): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (1): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (2): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (3): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (4): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (5): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (6): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (7): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (8): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
    )
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (graph_pred_linear): Linear(in_features=64, out_features=1, bias=True)
)
Name: convs.0.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.0.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.0.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.0.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.0.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.0.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.1.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.1.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.1.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.1.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.1.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.2.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.2.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.2.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.2.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.2.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.atom_embedding_list.0.weight, Shape: torch.Size([119, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.1.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.2.weight, Shape: torch.Size([12, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.3.weight, Shape: torch.Size([12, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.4.weight, Shape: torch.Size([10, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.5.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.6.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.7.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.8.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: atom_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.3, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.4, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.5, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.6, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.7, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.8, Shape: torch.Size([1, 64]), Requires Grad: True
Name: batch_norms.0.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.0.bias, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.1.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.1.bias, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.2.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.2.bias, Shape: torch.Size([64]), Requires Grad: True
Name: graph_pred_linear.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: graph_pred_linear.bias, Shape: torch.Size([1]), Requires Grad: True
/artic/h-ito/BingoGCN/__outputs__/Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molhiv_Msup_L3_M16_S3125/dump..Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molhiv_Msup_L3_M16_S3125.pth
0 train_acc 0.499825277740984
1 train_acc 0.6338182198536567
2 train_acc 0.6545337004559746
3 train_acc 0.6691566233192114
4 train_acc 0.6693028830479886
5 train_acc 0.6694094156971891
6 train_acc 0.6804572345933771
7 train_acc 0.6832029524755456
8 train_acc 0.6862266445780687
9 train_acc 0.6895456370337169
10 train_acc 0.6804196348348358
11 train_acc 0.6893389152528612
12 train_acc 0.6893938411441727
13 train_acc 0.6987799147472251
14 train_acc 0.6917943307048189
15 train_acc 0.6970056777429524
16 train_acc 0.698687401912559
17 train_acc 0.6919689119967782
18 train_acc 0.6985650040619017
19 train_acc 0.7028159809892339
20 train_acc 0.6987792227271292
21 train_acc 0.7088246633296603
22 train_acc 0.7080097968516059
23 train_acc 0.7194113020927098
24 train_acc 0.7108087362052201
25 train_acc 0.711201124414756
26 train_acc 0.7071973396286999
27 train_acc 0.7084580336459145
28 train_acc 0.6961125873636925
29 train_acc 0.698464917451742
30 train_acc 0.6897886770544179
31 train_acc 0.7059223951235855
32 train_acc 0.7069525567425723
33 train_acc 0.7097527007237607
34 train_acc 0.7181867597179101
35 train_acc 0.7250074123041378
36 train_acc 0.722459484017514
37 train_acc 0.7207177591425594
38 train_acc 0.7134543418468551
39 train_acc 0.7137488604735754
40 train_acc 0.7124664703448373
41 train_acc 0.7200168196765816
42 train_acc 0.7249385434894136
43 train_acc 0.7144813765602234
44 train_acc 0.7093028235855211
45 train_acc 0.7157701870976289
46 train_acc 0.7265917923135944
47 train_acc 0.7030304815885747
48 train_acc 0.7115958193579448
49 train_acc 0.7142351071124082
50 train_acc 0.71720184852408
51 train_acc 0.7319356483848968
52 train_acc 0.7259041806420552
53 train_acc 0.7204113992830877
54 train_acc 0.7278613672553724
55 train_acc 0.7209488938545745
56 train_acc 0.7164132019185463
57 train_acc 0.7223223230714785
58 train_acc 0.7150531773872028
59 train_acc 0.7228107482920945
60 train_acc 0.710667243725992
61 train_acc 0.7154702860923849
62 train_acc 0.7238213026750319
63 train_acc 0.7257358275309583
64 train_acc 0.7175384778551519
65 train_acc 0.7227829521515776
66 train_acc 0.728327378713995
67 train_acc 0.7261234484909451
68 train_acc 0.7236691095146919
69 train_acc 0.7317242106152397
70 train_acc 0.7204476790773721
71 train_acc 0.727238344126113
72 train_acc 0.7304499196846603
73 train_acc 0.7287384899116798
74 train_acc 0.721788916544632
75 train_acc 0.7308116027062395
76 train_acc 0.7363122782203745
77 train_acc 0.7394007767233556
78 train_acc 0.74061737368224
79 train_acc 0.7353731556895535
80 train_acc 0.723367017112478
81 train_acc 0.7258389257100536
82 train_acc 0.7290386856662237
83 train_acc 0.7337687711732519
84 train_acc 0.727598092054461
85 train_acc 0.7277966890067842
86 train_acc 0.7249709274668621
87 train_acc 0.7165261037156659
88 train_acc 0.7318649598136241
89 train_acc 0.7329336695149873
90 train_acc 0.7346756122481201
91 train_acc 0.7305755085168707
92 train_acc 0.7361140785388474
93 train_acc 0.7309693192121592
94 train_acc 0.7461227395548025
95 train_acc 0.7338254527451771
96 train_acc 0.7319101589780328
97 train_acc 0.7341280064941216
98 train_acc 0.734157878694926
99 train_acc 0.738452850159093
100 train_acc 0.7390674408953324 val_acc 0.7299474573780129 test_acc 0.6739991116089534
101 train_acc 0.737442090733164 val_acc 0.6590516607877719 test_acc 0.6739991116089534
102 train_acc 0.7373040199088543 val_acc 0.7226478297080148 test_acc 0.6739991116089534
103 train_acc 0.7361130148783296 val_acc 0.705400009798158 test_acc 0.6739991116089534
104 train_acc 0.7356736205630234 val_acc 0.7132079169116206 test_acc 0.6739991116089534
105 train_acc 0.7346247103255139 val_acc 0.6907976925338036 test_acc 0.6739991116089534
106 train_acc 0.739954520951908 val_acc 0.7394088036449147 test_acc 0.6939048649066224
107 train_acc 0.7446582968801069 val_acc 0.6774721977268272 test_acc 0.6939048649066224
108 train_acc 0.7295522927292165 val_acc 0.6846217911032726 test_acc 0.6939048649066224
109 train_acc 0.7415425789200222 val_acc 0.4630578826180678 test_acc 0.6939048649066224
110 train_acc 0.7430765311687901 val_acc 0.6729926023907504 test_acc 0.6939048649066224
111 train_acc 0.7401268724013363 val_acc 0.7283965926905742 test_acc 0.6939048649066224
112 train_acc 0.743081054929787 val_acc 0.6872550460513424 test_acc 0.6939048649066224
113 train_acc 0.7474077696120546 val_acc 0.7376175778953556 test_acc 0.6939048649066224
114 train_acc 0.7348353919991404 val_acc 0.7569168871252203 test_acc 0.6939048649066224
115 train_acc 0.7454599252700315 val_acc 0.6885517710170488 test_acc 0.6939048649066224
116 train_acc 0.7475933335192391 val_acc 0.6742265579071134 test_acc 0.6939048649066224
117 train_acc 0.7424990660291744 val_acc 0.6382948755633941 test_acc 0.6939048649066224
118 train_acc 0.7382366451398865 val_acc 0.6748542524005487 test_acc 0.6939048649066224
119 train_acc 0.7460735164216882 val_acc 0.6231230403684107 test_acc 0.6939048649066224
120 train_acc 0.7305760980154709 val_acc 0.5824055702527924 test_acc 0.6939048649066224
121 train_acc 0.7488886926171812 val_acc 0.6278812708210857 test_acc 0.6939048649066224
122 train_acc 0.7473224204668993 val_acc 0.6399054477758181 test_acc 0.6939048649066224
123 train_acc 0.747564012371474 val_acc 0.6957794434646287 test_acc 0.6939048649066224
124 train_acc 0.7454311295449317 val_acc 0.69130291005291 test_acc 0.6939048649066224
125 train_acc 0.7346202121948908 val_acc 0.732862409367039 test_acc 0.6939048649066224
126 train_acc 0.749827827963189 val_acc 0.6995609200470311 test_acc 0.6939048649066224
127 train_acc 0.7486256224592611 val_acc 0.6997170781893003 test_acc 0.6939048649066224
128 train_acc 0.7467264758276868 val_acc 0.6938596168920242 test_acc 0.6939048649066224
129 train_acc 0.7461361442403629 val_acc 0.6930971977268273 test_acc 0.6939048649066224
130 train_acc 0.7482653106626866 val_acc 0.6957886292377033 test_acc 0.6939048649066224
131 train_acc 0.7526160666356916 val_acc 0.7180671908681168 test_acc 0.6939048649066224
132 train_acc 0.7519319535101925 val_acc 0.6888013178522437 test_acc 0.6939048649066224
133 train_acc 0.7557210710994774 val_acc 0.7443813688026651 test_acc 0.6939048649066224
134 train_acc 0.7465846629687846 val_acc 0.7216710758377425 test_acc 0.6939048649066224
135 train_acc 0.7481801409301488 val_acc 0.7371552273172645 test_acc 0.6939048649066224
136 train_acc 0.753066930543327 val_acc 0.7505419606114051 test_acc 0.6939048649066224
137 train_acc 0.7554877578056791 val_acc 0.7531262247697432 test_acc 0.6939048649066224
138 train_acc 0.746837621944193 val_acc 0.6299603174603174 test_acc 0.6939048649066224
139 train_acc 0.7400323732126916 val_acc 0.7542882250636881 test_acc 0.697325170435891
140 train_acc 0.7306160301380391 val_acc 0.49999387615128355 test_acc 0.697325170435891
141 train_acc 0.7424338239123597 val_acc 0.7216465804428768 test_acc 0.697325170435891
142 train_acc 0.7403556619341376 val_acc 0.7466594405251812 test_acc 0.697325170435891
143 train_acc 0.7428871355207046 val_acc 0.7129905202821869 test_acc 0.697325170435891
144 train_acc 0.745809459494372 val_acc 0.7078924162257495 test_acc 0.697325170435891
145 train_acc 0.7432801901199624 val_acc 0.6804269547325102 test_acc 0.697325170435891
146 train_acc 0.7451974189803376 val_acc 0.6393420536939055 test_acc 0.697325170435891
147 train_acc 0.7379369107320732 val_acc 0.7251922888496961 test_acc 0.697325170435891
148 train_acc 0.7411872906767363 val_acc 0.7318979031941995 test_acc 0.697325170435891
149 train_acc 0.7443860126027624 val_acc 0.7118453605722125 test_acc 0.697325170435891
150 train_acc 0.7489161299324629 val_acc 0.7331808495002938 test_acc 0.697325170435891
151 train_acc 0.738218742323703 val_acc 0.6400524201450127 test_acc 0.697325170435891
152 train_acc 0.7391768185160383 val_acc 0.7297576180678033 test_acc 0.697325170435891
153 train_acc 0.745524885452733 val_acc 0.6353737997256516 test_acc 0.697325170435891
154 train_acc 0.7523128208666512 val_acc 0.7393322555359592 test_acc 0.697325170435891
155 train_acc 0.7471305771181043 val_acc 0.669045781893004 test_acc 0.697325170435891
156 train_acc 0.7389933947450763 val_acc 0.6756656623554771 test_acc 0.697325170435891
157 train_acc 0.7446377413202226 val_acc 0.7248248579267098 test_acc 0.697325170435891
158 train_acc 0.7490060156538021 val_acc 0.6886696551048401 test_acc 0.697325170435891
159 train_acc 0.74723835284044 val_acc 0.721205663335293 test_acc 0.697325170435891
160 train_acc 0.7501686863059578 val_acc 0.7174088771310992 test_acc 0.697325170435891
161 train_acc 0.7565399615462374 val_acc 0.6915356163041347 test_acc 0.697325170435891
162 train_acc 0.7502720664191661 val_acc 0.6936544679600235 test_acc 0.697325170435891
163 train_acc 0.7518487829468204 val_acc 0.67409489515971 test_acc 0.697325170435891
164 train_acc 0.7535509857851895 val_acc 0.5662569811875366 test_acc 0.697325170435891
165 train_acc 0.7496204526077983 val_acc 0.675717715069567 test_acc 0.697325170435891
166 train_acc 0.7554154288904754 val_acc 0.6840216539290613 test_acc 0.697325170435891
167 train_acc 0.7469134237750629 val_acc 0.6839940966098375 test_acc 0.697325170435891
168 train_acc 0.749866888653044 val_acc 0.5999626445228297 test_acc 0.697325170435891
169 train_acc 0.7501456061542423 val_acc 0.6933084705075446 test_acc 0.697325170435891
170 train_acc 0.7491983844252625 val_acc 0.6902802273172642 test_acc 0.697325170435891
171 train_acc 0.7518304828598412 val_acc 0.6930910738781109 test_acc 0.697325170435891
172 train_acc 0.7507404871329371 val_acc 0.6601968204977464 test_acc 0.697325170435891
173 train_acc 0.7464756569885007 val_acc 0.6487360376249265 test_acc 0.697325170435891
174 train_acc 0.7497392237605458 val_acc 0.6906262247697432 test_acc 0.697325170435891
175 train_acc 0.7540339004754127 val_acc 0.6174125514403292 test_acc 0.697325170435891
176 train_acc 0.7545891953415874 val_acc 0.7235082304526748 test_acc 0.697325170435891
177 train_acc 0.7516288615233956 val_acc 0.7279174015285126 test_acc 0.697325170435891
178 train_acc 0.7523085534093933 val_acc 0.7209331520674113 test_acc 0.697325170435891
179 train_acc 0.7529419824704646 val_acc 0.7114304698216735 test_acc 0.697325170435891
180 train_acc 0.7549001302228038 val_acc 0.7249044679600235 test_acc 0.697325170435891
181 train_acc 0.7528585556033534 val_acc 0.7170230746619635 test_acc 0.697325170435891
182 train_acc 0.7537176216612337 val_acc 0.707566321281599 test_acc 0.697325170435891
183 train_acc 0.7580529353339515 val_acc 0.7111196844993141 test_acc 0.697325170435891
184 train_acc 0.7507715767765027 val_acc 0.6424361282578875 test_acc 0.697325170435891
185 train_acc 0.7472891266111766 val_acc 0.6979381001371741 test_acc 0.697325170435891
186 train_acc 0.7529359337022195 val_acc 0.7249779541446209 test_acc 0.697325170435891
187 train_acc 0.7533358956872488 val_acc 0.6865018126592201 test_acc 0.697325170435891
188 train_acc 0.7526132601097472 val_acc 0.7008714236723496 test_acc 0.697325170435891
189 train_acc 0.7503025921945053 val_acc 0.5598177542621987 test_acc 0.697325170435891
190 train_acc 0.7534691736316353 val_acc 0.7799394963746816 test_acc 0.6990420826976188
191 train_acc 0.7646509753074928 val_acc 0.6390450470311582 test_acc 0.6990420826976188
192 train_acc 0.7585236627813754 val_acc 0.7116203091318832 test_acc 0.6990420826976188
193 train_acc 0.756964080158687 val_acc 0.4588599843229473 test_acc 0.6990420826976188
194 train_acc 0.7467612177995361 val_acc 0.7009724671761709 test_acc 0.6990420826976188
195 train_acc 0.751975960862214 val_acc 0.6538142391730354 test_acc 0.6990420826976188
196 train_acc 0.75988330285711 val_acc 0.7262210954340583 test_acc 0.6990420826976188
197 train_acc 0.753465418781856 val_acc 0.7305782137958063 test_acc 0.6990420826976188
198 train_acc 0.7554029212680022 val_acc 0.6981585586909661 test_acc 0.6990420826976188
199 train_acc 0.7603596177260487 val_acc 0.48363401430531056 test_acc 0.6990420826976188
Finished training!
Best validation score: 0.7799394963746816
Test score: 0.6990420826976188
GCN_graph_UGTs(
  (convs): ModuleList(
    (0): Graphlevel_GCNConv(64, 64)
    (1): Graphlevel_GCNConv(64, 64)
    (2): Graphlevel_GCNConv(64, 64)
  )
  (atom_encoder): SLT_AtomEncoder(
    (atom_embedding_list): ModuleList(
      (0): Embedding(119, 64)
      (1): Embedding(5, 64)
      (2): Embedding(12, 64)
      (3): Embedding(12, 64)
      (4): Embedding(10, 64)
      (5): Embedding(6, 64)
      (6): Embedding(6, 64)
      (7): Embedding(2, 64)
      (8): Embedding(2, 64)
    )
    (weight_scores_list): ParameterList(
        (0): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (1): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (2): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (3): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (4): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (5): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (6): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (7): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
        (8): Parameter containing: [torch.float32 of size 1x64 (GPU 0)]
    )
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (graph_pred_linear): Linear(in_features=64, out_features=1, bias=True)
)
Name: convs.0.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.0.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.0.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.0.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.0.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.0.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.0.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.1.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.1.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.1.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.1.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.1.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.1.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.lin.weight, Shape: torch.Size([64, 64]), Requires Grad: False
Name: convs.2.lin.weight_score, Shape: torch.Size([64, 64]), Requires Grad: True
Name: convs.2.bond_encoder.bond_embedding_list.0.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: convs.2.bond_encoder.bond_embedding_list.1.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: convs.2.bond_encoder.bond_embedding_list.2.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: convs.2.bond_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.bond_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.bond_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: convs.2.root_emb.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.atom_embedding_list.0.weight, Shape: torch.Size([119, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.1.weight, Shape: torch.Size([5, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.2.weight, Shape: torch.Size([12, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.3.weight, Shape: torch.Size([12, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.4.weight, Shape: torch.Size([10, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.5.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.6.weight, Shape: torch.Size([6, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.7.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: atom_encoder.atom_embedding_list.8.weight, Shape: torch.Size([2, 64]), Requires Grad: False
Name: atom_encoder.weight_scores_list.0, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.1, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.2, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.3, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.4, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.5, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.6, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.7, Shape: torch.Size([1, 64]), Requires Grad: True
Name: atom_encoder.weight_scores_list.8, Shape: torch.Size([1, 64]), Requires Grad: True
Name: batch_norms.0.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.0.bias, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.1.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.1.bias, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.2.weight, Shape: torch.Size([64]), Requires Grad: True
Name: batch_norms.2.bias, Shape: torch.Size([64]), Requires Grad: True
Name: graph_pred_linear.weight, Shape: torch.Size([1, 64]), Requires Grad: True
Name: graph_pred_linear.bias, Shape: torch.Size([1]), Requires Grad: True
/artic/h-ito/BingoGCN/__outputs__/Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molhiv_Msup_L3_M16_S3125/dump..Graph-level-SLT_structured_exp2_sparsity_GCN_graph_UGTs_HD64_ogbg-molhiv_Msup_L3_M16_S3125.pth
0 train_acc 0.4904305538867334
1 train_acc 0.6336236981307871
2 train_acc 0.65559101745613
3 train_acc 0.6611601516990068
4 train_acc 0.672815218229306
5 train_acc 0.6720852139193024
6 train_acc 0.6839732221029784
7 train_acc 0.6757044918358033
8 train_acc 0.6826439283899655
9 train_acc 0.6901545506421333
10 train_acc 0.6819070935853121
11 train_acc 0.6959858451646557
12 train_acc 0.6840827022451798
13 train_acc 0.7001830111219419
14 train_acc 0.6934716464501112
15 train_acc 0.6883543116235181
16 train_acc 0.6929654465651813
17 train_acc 0.6862980379846242
18 train_acc 0.6895409979360372
19 train_acc 0.7042916753980807
20 train_acc 0.6888313697733004
21 train_acc 0.6928084348945444
22 train_acc 0.696204933600928
23 train_acc 0.6958490430438551
24 train_acc 0.6986790464106609
25 train_acc 0.6933202606465498
26 train_acc 0.6996843337517578
27 train_acc 0.7062557565819826
28 train_acc 0.7011396263829637
29 train_acc 0.7097051820105122
30 train_acc 0.7121018270150702
31 train_acc 0.707382044918358
32 train_acc 0.7190948951266611
33 train_acc 0.7160522493626239
34 train_acc 0.7124878460766869
35 train_acc 0.7071110165293357
36 train_acc 0.7116185022388644
37 train_acc 0.7122834438446709
38 train_acc 0.707731515066764
39 train_acc 0.7238053605824534
40 train_acc 0.7055762312934154
41 train_acc 0.7164507247859658
42 train_acc 0.7141348539048181
43 train_acc 0.7153460556699923
44 train_acc 0.7196033120389352
45 train_acc 0.7118452926025
46 train_acc 0.7249292524788672
47 train_acc 0.7246168951118981
48 train_acc 0.7140036135751583
49 train_acc 0.7277421091255204
50 train_acc 0.7237990555104689
51 train_acc 0.732901183016043
52 train_acc 0.7302425699596434
53 train_acc 0.7272696644430439
54 train_acc 0.7240192844983807
55 train_acc 0.7318052666727634
56 train_acc 0.7303691071156889
57 train_acc 0.7237235612440862
58 train_acc 0.7233005319225282
59 train_acc 0.7238910429224695
60 train_acc 0.7115819661408407
61 train_acc 0.7131316682543829
62 train_acc 0.7279555076187825
63 train_acc 0.7213583134475805
64 train_acc 0.7204419635039879
65 train_acc 0.7301785709159639
66 train_acc 0.7321514176877466
67 train_acc 0.730699508265898
68 train_acc 0.7293599367729431
69 train_acc 0.7297786730068694
70 train_acc 0.7284993200774407
71 train_acc 0.72898309338519
72 train_acc 0.731452977183226
73 train_acc 0.7355578994247725
74 train_acc 0.7312278656090823
75 train_acc 0.7319118633978986
76 train_acc 0.7418894604006622
77 train_acc 0.7366513424369688
78 train_acc 0.7326615518350732
79 train_acc 0.7364993799499941
80 train_acc 0.7220818589033562
81 train_acc 0.7322039599542837
82 train_acc 0.7428128715122699
83 train_acc 0.7370421800088824
84 train_acc 0.7370427182467348
85 train_acc 0.7433030267831255
86 train_acc 0.7376205806571464
87 train_acc 0.7356221291418171
88 train_acc 0.733791287456741
89 train_acc 0.7340215891816038
90 train_acc 0.7344883439210699
91 train_acc 0.7361972362870323
92 train_acc 0.7335922419728744
93 train_acc 0.7295210108578465
94 train_acc 0.7343870783137101
95 train_acc 0.7388257464692622
96 train_acc 0.7370239311826511
97 train_acc 0.7372655230872257
98 train_acc 0.7434831826814129
99 train_acc 0.7416810982758755
100 train_acc 0.7425921939928145 val_acc 0.688305286106212 test_acc 0.6422970702408313
101 train_acc 0.7464321494287707 val_acc 0.7198645404663924 test_acc 0.7214063616524073
102 train_acc 0.7498106299822884 val_acc 0.6574135312561239 test_acc 0.7214063616524073
103 train_acc 0.7462817375794183 val_acc 0.7371613511659808 test_acc 0.7214063616524073
104 train_acc 0.7405247583260783 val_acc 0.6191394767783656 test_acc 0.7214063616524073
105 train_acc 0.7389212836880509 val_acc 0.5919189692337841 test_acc 0.7214063616524073
106 train_acc 0.7433146629728855 val_acc 0.7196042768959435 test_acc 0.7214063616524073
107 train_acc 0.7444323395036238 val_acc 0.6444860866157163 test_acc 0.7214063616524073
108 train_acc 0.7416644385328272 val_acc 0.7044814324906916 test_acc 0.7214063616524073
109 train_acc 0.7420327726364386 val_acc 0.7360590583970215 test_acc 0.726701944803878
110 train_acc 0.7498364141384524 val_acc 0.701349083872232 test_acc 0.726701944803878
111 train_acc 0.7399118720097042 val_acc 0.618533215755438 test_acc 0.726701944803878
112 train_acc 0.7414194506037081 val_acc 0.6170604301391338 test_acc 0.726701944803878
113 train_acc 0.7398224860806566 val_acc 0.6748665000979814 test_acc 0.726701944803878
114 train_acc 0.7502135010147577 val_acc 0.6716055506564765 test_acc 0.726701944803878
115 train_acc 0.7501377504446357 val_acc 0.6243355624142661 test_acc 0.726701944803878
116 train_acc 0.741457191329306 val_acc 0.676578115814227 test_acc 0.726701944803878
117 train_acc 0.7454611298976057 val_acc 0.6692662404467961 test_acc 0.726701944803878
118 train_acc 0.737062658677645 val_acc 0.6443483000195962 test_acc 0.726701944803878
119 train_acc 0.7488152487807119 val_acc 0.6701909416029785 test_acc 0.726701944803878
120 train_acc 0.7512533765454603 val_acc 0.7261935381148343 test_acc 0.726701944803878
121 train_acc 0.7482433582474238 val_acc 0.6802493631197334 test_acc 0.726701944803878
122 train_acc 0.7471201583711057 val_acc 0.7374736674505192 test_acc 0.7444002394793255
123 train_acc 0.7448089265876376 val_acc 0.7203452625906329 test_acc 0.7444002394793255
124 train_acc 0.7480789137683498 val_acc 0.6405163016852832 test_acc 0.7444002394793255
125 train_acc 0.7470670137907816 val_acc 0.6913825200862238 test_acc 0.7444002394793255
126 train_acc 0.7405928069688372 val_acc 0.6618227023319615 test_acc 0.7444002394793255
127 train_acc 0.7433153678081683 val_acc 0.647425533999608 test_acc 0.7444002394793255
128 train_acc 0.7434517982885471 val_acc 0.7334901038604742 test_acc 0.7444002394793255
129 train_acc 0.7468712618099637 val_acc 0.7109910836762687 test_acc 0.7444002394793255
130 train_acc 0.7492551557034964 val_acc 0.7030484518910445 test_acc 0.7444002394793255
131 train_acc 0.7508816720476782 val_acc 0.7385973936899862 test_acc 0.7444002394793255
132 train_acc 0.7452515503300577 val_acc 0.7552144571820497 test_acc 0.7444002394793255
133 train_acc 0.7463829647412172 val_acc 0.7190623162845384 test_acc 0.7444002394793255
134 train_acc 0.754275928096344 val_acc 0.6687885802469136 test_acc 0.7444002394793255
135 train_acc 0.755376867992912 val_acc 0.6800472761120909 test_acc 0.7444002394793255
136 train_acc 0.7566682287525225 val_acc 0.7158687291789143 test_acc 0.7444002394793255
137 train_acc 0.754155965131209 val_acc 0.5010533019792278 test_acc 0.7444002394793255
138 train_acc 0.7547274455785145 val_acc 0.6986943954536546 test_acc 0.7444002394793255
139 train_acc 0.7533319870552257 val_acc 0.7241175533999609 test_acc 0.7444002394793255
140 train_acc 0.7545594512926524 val_acc 0.6442227611209093 test_acc 0.7444002394793255
141 train_acc 0.7534576912241189 val_acc 0.7283246374681559 test_acc 0.7444002394793255
142 train_acc 0.7596687894425824 val_acc 0.7346015824025083 test_acc 0.7444002394793255
143 train_acc 0.7565549040542331 val_acc 0.7334135557515187 test_acc 0.7444002394793255
144 train_acc 0.7581741670025953 val_acc 0.6604234029002547 test_acc 0.7444002394793255
145 train_acc 0.7606853028874564 val_acc 0.6932931608857533 test_acc 0.7444002394793255
146 train_acc 0.7580369291654381 val_acc 0.7541672790515384 test_acc 0.7444002394793255
147 train_acc 0.7544412568233182 val_acc 0.7413500636880267 test_acc 0.7444002394793255
148 train_acc 0.7473942111442506 val_acc 0.7197956471683324 test_acc 0.7444002394793255
149 train_acc 0.754468053379252 val_acc 0.7280306927297668 test_acc 0.7444002394793255
150 train_acc 0.7599768665371069 val_acc 0.6991016313932981 test_acc 0.7444002394793255
151 train_acc 0.7552680542404326 val_acc 0.6447585978835978 test_acc 0.7444002394793255
152 train_acc 0.7549630656059656 val_acc 0.7222742749363119 test_acc 0.7444002394793255
153 train_acc 0.75589433242718 val_acc 0.7210678767391732 test_acc 0.7444002394793255
154 train_acc 0.7492234124853957 val_acc 0.7149960807368215 test_acc 0.7444002394793255
155 train_acc 0.7504281169507809 val_acc 0.7641307809131883 test_acc 0.7444002394793255
156 train_acc 0.7533831324663842 val_acc 0.7298341661767588 test_acc 0.7444002394793255
157 train_acc 0.7538167855779322 val_acc 0.719944150499706 test_acc 0.7444002394793255
158 train_acc 0.7561471248051579 val_acc 0.7429973789927494 test_acc 0.7444002394793255
159 train_acc 0.7544592109002494 val_acc 0.7412398344111306 test_acc 0.7521601421425673
160 train_acc 0.7569857890853975 val_acc 0.631286130707427 test_acc 0.7521601421425673
161 train_acc 0.7641387779150655 val_acc 0.7207280031354105 test_acc 0.7521601421425673
162 train_acc 0.7540324010985384 val_acc 0.6509528708602782 test_acc 0.7521601421425673
163 train_acc 0.7507565445621983 val_acc 0.6795543062904174 test_acc 0.7521601421425673
164 train_acc 0.7551431958738788 val_acc 0.7454469184793259 test_acc 0.7521601421425673
165 train_acc 0.7553042699587822 val_acc 0.7463808054085832 test_acc 0.7521601421425673
166 train_acc 0.7575998543989719 val_acc 0.7116647070350774 test_acc 0.7521601421425673
167 train_acc 0.7645551177090301 val_acc 0.7361233588085438 test_acc 0.7521601421425673
168 train_acc 0.756205408275453 val_acc 0.7209913286302174 test_acc 0.7521601421425673
169 train_acc 0.7610653244415757 val_acc 0.674927738585146 test_acc 0.7521601421425673
170 train_acc 0.7616208499811156 val_acc 0.7444824123064864 test_acc 0.7521601421425673
171 train_acc 0.7598043869358089 val_acc 0.6974941211052322 test_acc 0.7521601421425673
172 train_acc 0.751353078700011 val_acc 0.7444334215167548 test_acc 0.7521601421425673
173 train_acc 0.756685503624545 val_acc 0.7177579365079365 test_acc 0.7521601421425673
174 train_acc 0.7496901031489273 val_acc 0.710176611796982 test_acc 0.7521601421425673
175 train_acc 0.7505977772109478 val_acc 0.7189735204781501 test_acc 0.7521601421425673
176 train_acc 0.7553145221083505 val_acc 0.7419073339212228 test_acc 0.7521601421425673
177 train_acc 0.7468295355612211 val_acc 0.7160279492455418 test_acc 0.7521601421425673
178 train_acc 0.7572288034757246 val_acc 0.7398987115422301 test_acc 0.7521601421425673
179 train_acc 0.7517287302753768 val_acc 0.6596885410542818 test_acc 0.7521601421425673
180 train_acc 0.7533368952718317 val_acc 0.6688559425827943 test_acc 0.7521601421425673
181 train_acc 0.7539918538469962 val_acc 0.7353670634920635 test_acc 0.7521601421425673
182 train_acc 0.7583237074192346 val_acc 0.7383799970605526 test_acc 0.7521601421425673
183 train_acc 0.7491829421249754 val_acc 0.7338789682539683 test_acc 0.7521601421425673
184 train_acc 0.7562451609854038 val_acc 0.7039762149715852 test_acc 0.7521601421425673
185 train_acc 0.7583559119840656 val_acc 0.7301924113266706 test_acc 0.7521601421425673
186 train_acc 0.7536826490160192 val_acc 0.7053785763276503 test_acc 0.7521601421425673
187 train_acc 0.7493568698423998 val_acc 0.6992179845189105 test_acc 0.7521601421425673
188 train_acc 0.7595604498520205 val_acc 0.7339983833039389 test_acc 0.7521601421425673
189 train_acc 0.7588321755922565 val_acc 0.6767557074270037 test_acc 0.7521601421425673
190 train_acc 0.7520463418689997 val_acc 0.7362825788751715 test_acc 0.7521601421425673
191 train_acc 0.7560619422574332 val_acc 0.6820834558103076 test_acc 0.7521601421425673
192 train_acc 0.7628268487803839 val_acc 0.7548255927885557 test_acc 0.7521601421425673
193 train_acc 0.7594618626187353 val_acc 0.7236582647462277 test_acc 0.7521601421425673
194 train_acc 0.756771903615031 val_acc 0.6599947334901038 test_acc 0.7521601421425673
195 train_acc 0.759265944040487 val_acc 0.733903463648834 test_acc 0.7521601421425673
196 train_acc 0.7563525394369437 val_acc 0.7627192337840485 test_acc 0.7521601421425673
197 train_acc 0.7615761377938113 val_acc 0.7308047961983147 test_acc 0.7521601421425673
198 train_acc 0.7611310535354948 val_acc 0.7518983931020967 test_acc 0.7521601421425673
199 train_acc 0.7648400249455303 val_acc 0.7158151455026456 test_acc 0.7521601421425673
Finished training!
Best validation score: 0.7412398344111306
Test score: 0.7521601421425673
acc mean: 0.7309127896122624  acc std: 0.022949565044254567 ece mean: 0.0 ece std 0.0
End time: 2025-03-28 23:39:42
Duration: 0:39:56.070177
